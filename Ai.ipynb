{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP6GAK87tbS+FqG/WQVYWht",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya1602/Ai/blob/main/Ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOwmf8ucfmuW",
        "outputId": "5e341c4c-83bc-481a-eda2-8d3678e0705b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Hindi words in the corpus:  4983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#1\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "with open('1_Tagged_Hindi_Corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "words = word_tokenize(text)\n",
        "\n",
        "hindi_words = []\n",
        "for word in words:\n",
        "    if '\\u0900' <= word <= '\\u097f': \n",
        "        hindi_words.append(word)\n",
        "\n",
        "print(\"Total Hindi words in the corpus: \", len(hindi_words))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "with open('1_Tagged_Hindi_Corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "num_sentences = len(sentences)\n",
        "\n",
        "print(\"Total number of sentences in the corpus: \", num_sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6eXsq0Dhos4",
        "outputId": "d2e19ee9-2139-423b-f351-a462d42782a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of sentences in the corpus:  1101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "import unicodedata\n",
        "\n",
        "with open('1_Tagged_Hindi_Corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "full_chars = 0\n",
        "diacritic_marks = 0\n",
        "for char in text:\n",
        "    if unicodedata.category(char) == 'Mn': \n",
        "        diacritic_marks += 1\n",
        "    elif unicodedata.category(char)[0] == 'L': \n",
        "        full_chars += 1\n",
        "\n",
        "ratio = full_chars / diacritic_marks\n",
        "print(\"Ratio of full characters vs diacritic marks: \", ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWZJIIJZidl4",
        "outputId": "027eee7f-3490-4e57-b066-395d4b07f8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratio of full characters vs diacritic marks:  9.890054613394653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "import re\n",
        "\n",
        "with open(\"1_Tagged_Hindi_Corpus.txt\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "hindi_words = re.findall(r\"\\b[\\u0900-\\u097F]+\\b\", text)\n",
        "unique_words = set(hindi_words)\n",
        "num_unique_words = len(unique_words)\n",
        "\n",
        "print(\"Number of unique words in corpus:\", num_unique_words)\n",
        "print(\"Enlisted unique words in corpus:\", unique_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6coQGNPjaso",
        "outputId": "9cf3e7ed-f034-489f-ad66-0b2df3effd78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words in corpus: 1614\n",
            "Enlisted unique words in corpus: {'नय', 'कहत', 'आवास', 'अवध', 'खोज', 'ढाक', 'सुरक्ष', 'जाय', 'महंत', 'परिणामस्वरूप', 'ढोल', 'कर्जन', 'प्रोपेगंड', 'उसस', 'व्यक्त', 'तरह', 'सुलझान', 'सदन', 'पूर्ववर्त', 'अरुच', 'धमाक', 'बैध', 'जैस', 'जरूर', 'झाड', 'सूच', 'रवीन्द्रनाथ', 'कंप्यूटर', 'काम', 'जिमेदार', 'करघ', 'रूप', 'संध', 'र', 'जायेंग', 'जनत', 'लाए', 'आर्डर', 'शक्तिशाल', 'पुलिस', 'दलित', 'पहुचात', 'दोन', 'इंजन', 'पशुओ', 'यंत्रण', 'शीश', 'अग्रेश्वर', 'साक्षरत', 'अध्यात्म', 'अभिलेख', 'मनवाकर', 'पांच', 'ए', 'मेहमान', 'फिर', 'मिलिट्र', 'आवश्यकताओ', 'वंचित', 'निभ', 'प्रयास', 'सुधार', 'अधिकाधिक', 'मंत्र', 'अधिनियम', 'रद्द', 'मर', 'द्वीप', 'आरोप', 'प्रेम', 'सह', 'कितन', 'मानव', 'अनंत', 'साफ', 'सस्त', 'मैदान', 'जितन', 'अच्छ', 'हद', 'इस', 'साकार', 'दूर', 'लालस', 'दुबार', 'उन्होन', 'बकर', 'संग', 'यथासंभव', 'एस', 'सूअर', 'खिल', 'वाजपेय', 'निकाल', 'भोपाल', 'समय', 'भगवान', 'बगावत', 'उद्योग', 'अनुकूल', 'आरक्षण', 'अण्ड', 'अंतराल', 'तकनीक', 'अधिक', 'कानून', 'सर्कस', 'ठहर', 'सफाई', 'भिन्न', 'भैय', 'स्वर्ग', 'विष्ण', 'निर्भर', 'पश', 'प्रवेश', 'उत्कीर्णित', 'छिप', 'आरएसएस', 'सामाजिक', 'अधिनिर्णायक', 'अत', 'प्रभावकार', 'ह', 'सरकार', 'रिस', 'मकसद', 'आसन्न', 'मैजिस्ट्रेट', 'सुधर', 'कोतवाल', 'हालात', 'विकल्प', 'मालूम', 'उमीद', 'सरल', 'पैद', 'अलग', 'समक्ष', 'प्रतिद्वंद्व', 'बुद्ध', 'लक्ष्य', 'कारन', 'महात्म', 'प्रिय', 'मनुष्य', 'पराजित', 'मात्र', 'हस्तांतरण', 'कारखान', 'झुंड', 'रहिए', 'रेणुक', 'थ', 'लेकिन', 'शांत', 'रक्त', 'किल', 'कान', 'साधन', 'त्रुट', 'सामग्र', 'रचन', 'जानवर', 'लैफ्टिनेंट', 'बह', 'इंतजार', 'वैविध्यकरण', 'सावरकर', 'ख़ास', 'स्तंभ', 'देखबाल', 'अधिसूचन', 'सितंबर', 'उपलब्ध', 'होत', 'आयातित', 'विवाद', 'वत्स', 'सेवन', 'जहाज', 'विध', 'संभाल', 'एकत्रित', 'देखिए', 'शक्तिय', 'गांव', 'पालक', 'खुद', 'प्रस्तावित', 'विपक्ष', 'विनिर्दिष्ट', 'शुर', 'आय', 'संघ', 'रक्ष', 'उपयोगम', 'ग्रह', 'अनुरोध', 'परछाई', 'मुकाबल', 'म', 'शामिल', 'ठंड', 'आर्थिक', 'घास', 'बहुमत', 'उपेक्षित', 'कायम', 'आमदन', 'आश्वासन', 'परंपरित', 'चाहिए', 'निम्नलिखित', 'पहुंचान', 'निश्चय', 'सावधान', 'पाई', 'उल्लास', 'स्थायित्व', 'विदेश', 'सन', 'प्रतिवाद', 'सत्र', 'सक', 'सुभाष', 'आरम्भ', 'सुर्खिय', 'घुम', 'सूख', 'शान्त', 'लाइलाज', 'ड्रग्स', 'दक्षिण', 'संपूर्ण', 'ब्रिटिश', 'पढ', 'धर्म', 'ईर्ष्य', 'आवर्धन', 'सर्वोच्च', 'विपत्त', 'कोयल', 'ब्लेयर', 'दूषित', 'किंत', 'इंसुलिन', 'मानकर', 'ज्ञात', 'किस्म', 'कलाकृत', 'जहरील', 'बावजूद', 'बढय', 'एकड', 'अनुच्छेद', 'बहुत', 'पुरान', 'देखत', 'अर्थबोध', 'आत्म', 'अपेक्षाकृत', 'आवश्यकत', 'महीन', 'सदैव', 'न्यायाधीश', 'असीम', 'प्रसाद', 'मुय', 'प्रणाल', 'स्वाधीनत', 'व्यस्त', 'निबटन', 'अगुआई', 'संसार', 'सरीख', 'प्राकृतिक', 'अनुसूच', 'छुट्ट', 'गिरफ्तार', 'ऋण', 'नलिन', 'लिए', 'जिसन', 'आज', 'बदतरीन', 'प्रेरण', 'खरीद', 'क्लिक', 'इसन', 'कलाकृतिय', 'जाम', 'किए', 'ग्रन्थ', 'इसम', 'स्मृत', 'कारीगर', 'गत', 'सौदागर', 'छूत', 'तेरह', 'राजदरबार', 'माह', 'गुजर', 'रेलव', 'द्वार', 'देर', 'छ', 'चिंत', 'हव', 'निर्गम', 'प्रश्न', 'बुर', 'यद्यप', 'बढ़िय', 'अभ', 'कहन', 'बगैर', 'दह', 'संभावन', 'इतिहास', 'आकर्षित', 'ब्रितान', 'कज', 'खतर', 'ठीक', 'दुगुन', 'सकत', 'द्वितीय', 'रहत', 'ल', 'संख्य', 'शिश्न', 'हाल', 'बहन', 'लाभप्रद', 'डीलर', 'भारतीय', 'राय', 'बाह्य', 'उन्होंन', 'सोनिय', 'संरक्षण', 'निश्चित', 'बनकर', 'बाजार', 'खुल', 'प्रभाव', 'सम्मिलित', 'करव', 'अंशमात्र', 'मधुर', 'निकालन', 'प्रारम्भ', 'थोड', 'फलक', 'नकद', 'सेल्युकस', 'शिकार', 'मुखबिर', 'सहन', 'लाय', 'पढ़न', 'तीव्र', 'युग', 'मिल', 'पूछ', 'अपेक्ष', 'हिमवंत', 'स', 'परेशान', 'पिंजर', 'चाह', 'नेत', 'उमसभर', 'व्यापारिय', 'पात', 'बाध', 'बसेंग', 'देखभाल', 'आकार', 'योगदान', 'प्रतिशत', 'सामान्य', 'प्रमेह', 'आप', 'मन', 'स्थानीय', 'कमाय', 'वाल', 'गीत', 'बाबूलाल', 'चरण', 'पवित्र', 'परिवार', 'दृश्य', 'प्रमाण', 'यात्र', 'वापिस', 'बंगाल', 'बर्लिन', 'कारण', 'आशंक', 'कवित', 'बेमान', 'नियत', 'कायद', 'कोल', 'छाए', 'मुँह', 'विघ्न', 'भुगतन', 'अवस्थ', 'कई', 'प्रत्येक', 'निगरान', 'अस्तबल', 'संभालन', 'निकलत', 'स्वास्थ्य', 'चूक', 'अफ्रीक', 'दिए', 'अहोरात्र', 'कार्यक्रम', 'मोहक', 'इंजक्शन', 'जह', 'पहल', 'गुर', 'अलव', 'जयेंद्र', 'अंदर', 'प्रक्षिप्त', 'नीत', 'जिसक', 'किस', 'नियमित', 'पुरूष', 'जानत', 'कीट', 'मधुमेह', 'न', 'चाहत', 'हेलन', 'पूछन', 'उचित', 'शिव', 'प्रयोग', 'पड़त', 'कभार', 'दर', 'ऊपर', 'उस', 'प्रतिम', 'शार्टहैंड', 'सेन', 'बतात', 'वाद', 'आरेख', 'चुक', 'उदास', 'भावनात्मक', '१', 'विलियम', 'सामन्यतय', 'पुरुल', 'देनेवाल', 'लिप', 'अधीन', 'स्थित', 'चिकित्सक', 'प्रकट', 'प्रासंगिक', 'यह', 'पुरुष', 'करान', 'सच्चाई', 'खराब', 'रखन', 'धूल', 'उत्पाद', 'पद्धत', 'स्पष्ट', 'नई', 'मिलन', 'घ्राण', 'उदासीनत', 'परमहंस', 'कमजोर', 'दिख', 'एच', 'माद', 'वर्तमान', 'बच्च', 'तंत्रिक', 'लिपिय', 'वास्तविक', 'कबूल', 'आग', 'आर्ट', 'दुर्ग', 'भूमिक', 'अर्थात', 'उत्सुकत', 'देत', 'गरम', 'लेखक', 'बजट', 'पारित', 'ओर', 'चुरान', 'संपर्क', 'उठाकर', 'इनकार', 'परियोजन', 'सैंडर्स', 'विक्रमादित्य', 'हेत', 'उच्च', 'उग', 'बल', 'मुलायम', 'खासकर', 'उत्तरदायित्व', 'अनुकूलित', 'झाडिय', 'हालंक', 'लगभग', 'पौध', 'जेन', 'रोग', 'हिस्स', 'विद्यार्थ', 'कलकत्त', 'उर्वरक', 'कृपय', 'जिन्ह', 'कम', 'शिक्ष', 'पास', 'खराद', 'सिद्ध', 'मशीन', 'जोए', 'बनाए', 'प्रकाशित', 'देसाई', 'नकार', 'महादेव', 'लगान', 'लिखित', 'विजय', 'वस्तुओ', 'समीक्ष', 'प्राय', 'अत्यधिक', 'तय', 'व्यापार', 'अंतर्राष्ट्रीय', 'बेहतर', 'पैराग्राफ', 'कर्तव्य', 'नियंत्रण', 'शारीरिक', 'जर्मन', 'अनिवार्य', 'शताब्दिय', 'साक्ष्य', 'जंत', 'परिवर्तन', 'कारगर', 'कम्प्यूटर', 'समत', 'मूल', 'स्थापन', 'न्यायालय', 'कथन', 'उनम', 'पड', 'नागरिक', 'गई', 'स्वभाविक', 'गठन', 'राष्ट्रीय', 'अमेरिक', 'सीम', 'हफ्त', 'कंपनिय', 'घट', 'मौसम', 'बेचन', 'खबर', 'वित्त', 'संयंत्र', 'बात', 'बंबई', 'घोषणापत्र', 'समितिय', 'बांटकर', 'उनक', 'महाजन', '२०', 'ऐड', 'उड़ान', 'कर्म', 'दांए', 'द्योतक', 'संबंधिय', 'सामरिक', 'आधुनिक', 'बचाव', 'ध्यान', 'पान', 'बहुमूल्य', 'विद्यमान', 'निबट', 'सीख', 'फिसल', 'पाकिस्तान', 'उन', 'कव', 'भ', 'प्रतिष्ठ', 'बीच', 'केंद्र', 'विकास', 'गए', 'जीवन', 'सम्पर्क', 'सार्वजनिक', 'समाधान', 'अंतत', 'साल', 'जिसस', '२', 'एवज', 'मृग', 'हडसन', 'मलमल', 'परंत', 'कविताओ', 'उत्तराधिकारिय', 'तीन', 'एव', 'परियोजनाओ', 'औद्योगिक', 'लागत', 'इटल', 'स्रोत', 'व्याख्यान', 'मुस्लिम', 'कुछ', 'चिकीत्स', 'जाएग', 'संकेत', 'मुकदम', 'नौकर', 'उद्यान', 'दौरान', 'मोह', 'बढ', 'मानक', 'नह', 'उत्सर्जन', 'अधिकांश', 'तरीक', 'निज', 'स्वीकार', 'हृदय', 'प्रतीत', 'शासक', 'सफल', 'राज्य', 'भोजन', 'आयेंग', 'आचरण', 'रवान', 'आदेश', 'कंपन', 'बताई', 'मायन', 'प्रारूप', 'सीप', 'मुर्गीपालन', 'करन', 'उपाय', 'मिथाइल', 'अभिप्राय', 'क्रांतिकार', 'आम', 'माल', 'वरन', 'काट', 'उत्परिवर्तन', 'ख', 'मुंह', 'भुगतान', 'अंतर्गत', 'लेट', 'गुट', 'ढंग', '१५', 'बनत', 'न्यायिक', 'हम', 'मानसरोवर', 'भौतिक', 'केलर', 'ड्राईव', 'बोर्ड', 'देखन', 'विधानमंडल', 'छोट', 'होग', 'व्यग्रत', 'ऊंच', 'देख', 'किसक', 'समझ', 'मस्जिद', 'दीवार', 'अंत', 'उतन', 'वाद्य', 'सौतेल', 'आई', 'लगाए', 'सहज', 'परिवर्तित', 'चिकित्स', 'उनस', 'जिन्होंन', 'अकबर', 'आलोचन', 'पृथक', 'मार्गदर्शक', 'पत्त', 'अंड', 'आदिवासिय', 'जान', 'मुर्ग', 'रखेंग', 'अपवाद', 'सिल्क', 'मंद', 'व्यक्तित्व', 'निर्धारण', 'इज', 'द', 'बधाई', 'गरीब', 'प्रदूषण', 'खरीदत', 'परिवेश', 'तरफ', 'रामचंद्र', 'प्रक्रिय', 'छीन', 'लाग', 'पाँचव', 'द्रविड', 'लिय', 'काफ', 'संघवाद', 'विचारण', 'विवेकानुसार', 'हिन्द', 'लगातार', 'उल्लिखित', 'बढन', 'संस्थ', 'चिद', 'इसक', 'जात', 'तस्वीर', 'राष्ट्रपतीय', 'पाबंद', 'आवश्यक', 'ढक', 'अंतिम', 'प', 'घुमात', 'प्रतिक्रिय', 'निर्बाध', 'इन्ह', 'वर्चस्व', 'व्यक्तिय', 'तभ', 'उत्पन्न', 'अनुमत', 'मुर्गिय', 'भारत', 'दोहर', 'सत्य', 'संख्यात्मक', 'अतिरिक्त', 'शायद', 'काष्ठ', 'उपभोक्त', 'आवाज', 'रसायन', 'रख', 'कार्यपालिक', 'स्पष्टतय', 'पुण्य', 'एक्ट', 'समाप्त', 'शैल', 'अंग्रेज', 'महल', 'विधान', 'हाथ', 'निष्कर्ष', 'दिखाई', 'उसन', 'प्रसिद्ध', 'ऐस', 'नजर', 'सौद', 'श्रुत', 'सलह', 'आधार', 'फोर्ड', 'संकल्पन', 'विभिन्न', 'रोम', 'ऊर्ज', 'वर्ष', 'हित', 'आधारित', 'लेकर', 'गैस', 'भर', 'अनुसार', 'महिल', 'दिखात', 'फॉर्म', 'प्रेषित', 'किसान', 'प्रबंधन', 'जब', 'स्वतन्त्रत', 'भीतर', 'खामोश', 'परन्त', 'फीसद', 'प्राधिकृत', 'नेतृत्व', 'मानसिक', 'गजलक्ष्म', 'जोखिम', 'चलिए', 'लार्ड', 'धमक', 'बहस', 'निष्कासन', 'परंपरागत', 'भेजन', 'समस्याए', 'दुकान', 'अप्रासंगिक', 'बुराई', 'रोक', 'इसस', 'बंधन', 'अधिकारित', 'तत्कालीन', 'मुख्य', 'ज', 'आत', 'गीतकार', 'इन्होंन', 'अन्त', 'मौक', 'मद्रास', 'सीमित', 'दीय', 'मतभेद', 'मुद्राओ', 'फैलान', 'सोविएत', 'संगठन', 'ताक', 'मुआवज', 'आपक', 'क', 'उपबंध', 'भविष्य', 'घोड', 'अंबेडकर', 'समस्य', 'हट', 'मृदंग', 'निभात', 'ग्रामीण', 'वह', 'रियासत', 'अनुयाय', 'भुगत', 'प्लैटफॉर्म', 'विशुद्ध', 'लेख', 'ताज', 'बाहर', 'कसाव', 'होन', 'हर्ष', 'संसदीय', 'पूराण', 'संबंध', 'प्रारंभिक', 'मदद', 'सेव', 'नेशनल', 'मारन', 'लोकमत', 'निकलन', 'तिथ', 'संग्रहालय', 'लाल', 'बहाल', 'बिपिन', 'गय', 'ज्ञान', 'सुषम', 'अधूर', 'महत्त्वपूर्ण', 'उत्कृष्ट', 'झिल्ल', 'करिश्म', 'सार', 'देन', 'युव', 'बंटवार', 'बतान', 'गंभीर', 'आध', 'खुराक', 'विकासात्मक', 'भेज', 'भुट्ट', 'तथ', 'तत्व', 'तक', 'संतान', 'स्कूल', 'दर्शात', 'कार्रवाई', 'मरन', 'शीघ्र', 'पैस', 'सहयोग', 'गिर', 'मानत', 'निवासिय', 'यूरोप', 'बाल', 'बदल', 'संबोधित', 'शेयर', 'उच्चतम', 'हत', 'कोई', 'चुर', 'लगत', 'गांध', 'संविधान', 'बाए', 'प्रजनक', 'करक', 'आजाद', 'अम्पायर', 'मनोभाव', 'जेल', 'आ', 'इसलिय', 'जल', 'घर', 'उल्लेख', 'संक्षिप्त', 'गाँव', 'केवल', 'नतीज', 'जुर्मान', 'जन्म', 'इन', 'अनुदार', 'प्रजात', 'गैर', 'जार', 'सूचन', 'मिक', 'बड', 'फ्रांस', 'कांग्रेस', 'ज्याद', 'बिक', 'सवाल', 'लगाय', 'महत्व', 'मानसून', 'इसलिए', 'कुमार', 'टिप्पणिय', 'तंतुओ', 'हुआ', 'कार', 'सक्षम', 'सुलह', 'गुप्त', 'प्रतिनिधिय', 'अनुपस्थित', 'दुनिय', 'अनामिक', 'मेंडेल', 'कार्यविधिय', 'पहुँच', 'अविश्वसनीय', 'अगर', 'विचार', 'जोश', 'नष्ट', 'अनाज', 'वैज्ञानिक', 'श्र', 'गलत', 'जीन', 'समित', 'पारंपरिक', 'गरिम', 'सोच', 'पृष्ठ', 'अयोध्य', 'कार्यविध', 'बिन', 'नरेंद्र', 'खार', 'प्रमुख', 'भाभ', 'मूलभूत', 'मंडप', 'निर्णय', 'समझाय', 'मात', 'चूकत', 'खपत', 'घटन', 'इंफार्मेशन', 'शीध्र', 'सजीव', 'इंदिर', 'गवर्नर', 'हक्सर', 'आर', 'नद', 'उदार', 'उन्नत', 'घटत', 'पार्ट', 'लयबद्ध', 'स्थितिय', 'सामन', 'मूर्खत', 'समागम', 'विपरीत', 'पंक', 'कीजिए', 'आकस्मिक', 'क्षत', 'सुचार', 'ढूंढन', 'सद', 'निभान', 'गैरसरकार', 'मिलत', 'औसत', 'सुस्थापित', 'खरीदन', 'समाजवाद', 'पाल', 'मान', 'वितरण', 'शरद', 'प्रावस्थ', 'विरोध', 'अध्यक्ष', 'प्राण', 'प्रचंड', 'छोड़कर', 'भाजप', 'लोलक', 'विद्यार्थिय', 'रह', 'मांगन', 'लेटन', 'अधिकरण', 'घमंड', 'नेपाल', 'गर्म', 'आश्चर्य', 'टाइपराइटर', 'संश्लेषित', 'अपराध', 'दब', 'संयुक्त', 'रात', 'रूस', 'मार', 'बनाम', 'उपयोग', 'काटत', 'शासन', 'संबंधित', 'दुर्गुण', 'साथ', 'खट्ट', 'क्लर्क', 'फिसलकर', 'सहायत', 'तुल', 'हमार', 'सीध', 'इच्छ', 'हक', 'दुर्लभ', 'सफलत', 'हस्पताल', 'जंतुओ', 'मसलन', 'महत्वपूर्ण', 'वास्तव', 'नात', 'छह', 'दास', 'उजाल', 'उपेक्ष', 'आतंकवाद', 'चलाय', 'देश', 'तिथिय', 'जिनक', 'वृद्ध', 'अयोध्यावासिय', 'लेन', 'कोशिश', 'यद', 'शाख', 'कोशिकाओ', 'विशेष', 'अनेक', 'उच्चकोट', 'गन्ध', 'आए', 'वजन', 'अथव', 'स्वाधीन', 'कोशिक', 'शताब्द', 'दाव', 'पूर', 'असीस', 'नीच', 'उत्पादन', 'इनक', 'जाँच', 'डाट', 'नियुक्त', 'ग', 'बिकन', 'लेत', 'शिकायत', 'पत्तिय', 'सरस्वत', 'सोचेंग', 'संचालन', 'सम्राट', 'वोट', 'सेनापत', 'स्तर', 'अतिशय', 'बनात', 'तौर', 'स्त्रोत', 'अधिकारिय', 'असहमत', 'वेद', 'कहान', 'देवर', 'निर्दोष', 'इंडिय', 'होकर', 'कनाड', 'पेशकश', 'अनुसंधान', 'समस्याओ', 'पूर्त', 'बाद', 'दृष्ट', 'मौजूद', 'आन', 'धरत', 'शब्द', 'जामिन', 'विश्वयुद्ध', 'सपन', 'वैकल्पिक', 'दूसर', 'बार', 'अनूठ', 'दौर', 'बेलजियम', 'शास्त्र', 'उलझन', 'शिकाग', 'प्रदान', 'चर', 'ग्रंथ', 'कराए', 'पीछ', 'अराजकतावाद', 'जबलपुर', 'महसूस', 'गहमागहम', 'जापान', 'भरत', 'ई', 'सर्वर', 'आंतरिक', 'कर', 'सकारात्मक', 'निर्धारित', 'विधिय', 'बाक', 'टैरिफ', 'प्रदेश', 'कश्मीर', 'जाए', 'पक्ष', 'चिन्ह', 'दिन', 'बैट्र', 'एल', 'अकाल', 'संघात्मक', 'बिल', 'उठ', 'चिरकालिक', 'हिंद', 'मूल्य', 'कदम', 'बनाय', 'बैठ', 'राजनीतिक', 'फैल', 'भूम', 'विषय', 'विधेयक', 'नागनाथेश्वर', 'विस्तृत', 'सदगुण', 'साधक', 'सब', 'मेज', 'उत्तरार्ध', 'इंडियन', 'हथकरघ', 'काल', 'अपर', 'तुच्छ', 'चावल', 'चार', 'अटक', 'चल', 'चुनाव', 'पोर्ट', 'फसल', 'अपर्याप्त', 'खिलाय', 'लोग', 'नेहर', 'विद्वान', 'युध', 'एक', 'संग्रह', 'विकसित', 'उत्पादित', 'समूह', 'पुष्ट', 'अर्थ', 'गारिम', 'साक्ष', 'वैस', 'तंत', 'कंगन', 'प्रवृत्त', 'रेश', 'उत्तम', 'विराजित', 'जल्द', 'उठाय', 'दिग्गज', 'मुद्र', 'चंद्रभान', 'स्वय', 'किय', 'मनस्थित', 'इस्तेमाल', 'प्रतिष्ठित', 'बत', 'उत्तराधिकार', 'पहिल', 'कष्टकर', 'चरत', 'विशेषकर', 'आवेशपूर्ण', 'जाँचिए', 'कभ', 'बनाई', 'प्रतिध्वन', 'लन', 'कार्यकलाप', 'होंग', 'सदस्य', 'अधिकतम', 'प्राचीन', 'आँध', 'क्योंक', 'व्यवहार', 'वस्त', 'भाग', 'मित्रत', 'लग', 'आंध', 'गवर्नमेंट', 'महिलाओ', 'यान', 'प्रोग्राम', 'समूच', 'विश्वविद्यालय', 'धारण', 'क्य', 'सलाह', 'चर्च', 'पैर', 'प्रत', 'प्राप्त', 'दंभ', 'प्रकृत', 'दूध', 'पद', 'संभावनाओ', 'आरंभ', 'उन्ह', 'निकास', 'उम्र', 'चेतन', 'सीमाओ', 'घटनाओ', 'सूचकांक', 'उसक', 'क्षतिपूर्त', 'मामल', 'अब', 'पर', 'मनव', 'मुलाकात', 'हर', 'फरवर', 'अपन', 'शेयरधारक', 'पूंजीपतिय', 'कौंसिल', 'तत्पश्चात', 'य', 'निर्माण', 'तेज', 'स्थिर', 'वर्ग', 'जिन', 'तुरंत', 'हमेश', 'परिचित', 'जिसम', 'जटिल', 'चलाकर', 'गाँवघर', 'शहर', 'पदार्थ', 'मुझ', 'जबक', 'मंच', 'दैनंदिन', 'ऐडम्स', 'नाम', 'एन', 'जमींदारिय', 'स्वागत', 'मध्यस्थ', 'खान', 'सिक्योरिट', 'तर्कसंगत', 'अनुमान', 'पत', 'दिल्ल', 'सुपरिंटेंडेंट', 'आद', 'सहायक', 'विश्वसनीय', 'अनुवाद', 'दीए', 'पूर्व', 'चलन', 'बस', 'हुई', 'आदम', 'तंत्रिकाओ', 'राष्ट्र', 'गंध', 'अन्य', 'आर्य', 'बदलकर', 'जानकार', 'अदालत', 'दस', 'विभाग', 'घाट', 'ताजमहल', 'नेक्टर', 'राम', 'दिय', 'मुसलमान', 'आव', 'वापस', 'हान', 'पिछल', 'बन', 'करत', 'पित', 'हत्यार', 'पत्र', 'कह', 'तराश', 'उत्तेजक', 'बसाय', 'मृत्य', 'हवाल', 'अदायग', 'संशोधन', 'ब्रह्म', 'हस्तक्षेप', 'बताय', 'टैस्ट', 'ब्यूर', 'न्याय', 'स्थान', 'पहुँचान', 'प्रतिनिध', 'शर्त', 'रिसन', 'सीखेंग', 'साधारण', 'सुनवाई', 'अमरत्व', 'निष्पक्षत', 'श्रमिक', 'रिपोर्ट', 'भाष', 'जिस', 'स्मरणीय', 'बिजल', 'दुर्घटन', 'गठित', 'दोष', 'कुल', 'कोक', 'अपील', 'घ', 'अपमानित', 'स्वतंत्रत', 'त', 'संबद्ध', 'सबस', 'जलाए', 'इतन', 'तहत', 'लान', 'पूछकर', 'पूर्वाध', 'निधन', 'गुटिक', 'व', 'छीनकर', 'हुए', 'औचित्य', 'विश्लेषण', 'मगर', 'यव', 'पहुंच', 'सुलझ', 'संस्थाओ', 'रजिस्टर', 'रचनाकार', 'उल्लेखनीय', 'अनुताप', 'प्रयत्न', 'भाप', 'युद्ध', 'सचाई', 'शक्कर', 'मानन', 'शिल्प', 'शोर', 'शरीर', 'खर्च', 'संसद', 'संचरण', 'अरण्य', 'होनेवाल', 'अस्पष्ट', 'कहकर', 'धार', 'कसरत', 'कमेट', 'दोहरान', 'स्थापित', 'व्यवस्थ', 'कार्य', 'प्रारंभ', 'आमंत्रित', 'सिकन्दर', 'रहन', 'प्रथम', 'बढ़ान', 'पहनत', 'प्रजातिय', 'पाप', 'सेंट', 'आंदोलन', 'बहुध', 'मंदिर', 'उपद्रव', 'जाकर', 'राज', 'अधिकार', 'आनुवंशिक', 'विशेषताओ', 'ग्रहण', 'फ्र', 'मुकम्मिल', 'क्षेत्र', 'मुकद्दम', 'नाइट्रोजनयुक्त', 'पश्चात', 'जनवर', 'जिल', 'पहन', 'नागपुर', 'तब', 'सुनिश्चित', 'आकृत', 'कायल', 'एडीसन', 'नियम', 'कमीशन', 'आश', 'गौतम', 'विशेषाधिकार', 'जन', 'बेच', 'इनम', 'आवृत', 'ब्यौर', 'तरक्क', 'उद्देश्य', 'औपचारिक', 'चलत', 'प्रकार', 'योजन', 'चीज', 'मर्ज', 'स्वाभाविक', 'पूंज', 'सभ', 'अंश', 'लक्षण', 'विरुद्ध', 'पर्याप्त', 'मत', 'नांबियार', 'नेताओ', 'प्रचार', 'त्रुटिय', 'प्रांतीय', 'आइसोसाइनेट', 'छूट', 'आयुर्वेद', 'स्वराज', 'मेर', 'निकल', 'फ्रांसिस', 'तैयार', 'उगत', 'प्रस्थान', 'प्राणिय', 'विस्तार', 'तुलन', 'ठहराएग', 'गुणवत्त', 'और', 'सोचन', 'बीत', 'उसम', 'प्रगत'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "import re\n",
        "\n",
        "with open(\"1_Tagged_Hindi_Corpus.txt\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "hindi_words = re.findall(r\"\\b[\\u0900-\\u097F]+\\b\", text)\n",
        "long_words = [word for word in hindi_words if len(word) > 13]\n",
        "\n",
        "print(\"Enlisted words with length greater than 13 characters:\", long_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQLzHMfykWiY",
        "outputId": "037f3b36-767b-4377-81a4-444c0ecfb8e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enlisted words with length greater than 13 characters: ['नाइट्रोजनयुक्त', 'नाइट्रोजनयुक्त', 'अंतर्राष्ट्रीय', 'अंतर्राष्ट्रीय']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "import re\n",
        "\n",
        "with open(\"1_Tagged_Hindi_Corpus.txt\", encoding=\"utf8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "nn_count = len(re.findall(r'\\bNN\\S*\\b', text))\n",
        "v_count = len(re.findall(r'\\bV\\S*\\b', text))\n",
        "psp_count = len(re.findall(r'\\bPSP\\S*\\b', text))\n",
        "\n",
        "print(\"Number of nouns:\", nn_count)\n",
        "print(\"Number of verbs:\", v_count)\n",
        "print(\"Number of prepositions:\", psp_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoYpbFxfkpQ2",
        "outputId": "91e95467-2454-44e1-c245-cd32f639995b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nouns: 1344\n",
            "Number of verbs: 988\n",
            "Number of prepositions: 922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "import re\n",
        "\n",
        "\n",
        "with open(\"1_Tagged_Hindi_Corpus.txt\", encoding=\"utf8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "i_count = len(re.findall(r'\\b\\S*[ि]\\b', text))\n",
        "u_count = len(re.findall(r'\\b\\S*[ू]\\b', text))\n",
        "r_count = len(re.findall(r'\\b\\S*[ृ]\\b', text))\n",
        "\n",
        "i_words = re.findall(r'\\b\\S*[ि]\\b', text)\n",
        "i_top_10 = sorted(i_words, key=i_words.count, reverse=True)[:10]\n",
        "u_words = re.findall(r'\\b\\S*[ू]\\b', text)\n",
        "u_top_10 = sorted(u_words, key=u_words.count, reverse=True)[:10]\n",
        "r_words = re.findall(r'\\b\\S*[ृ]\\b', text)\n",
        "r_top_10 = sorted(r_words, key=r_words.count, reverse=True)[:10]\n",
        "\n",
        "\n",
        "print(\"Number of words that end with ि:\", i_count)\n",
        "print(\"Number of words that end with ू:\", u_count)\n",
        "print(\"Number of words that end with ृ:\", r_count)\n",
        "print(\"Top 10 words that end with ि:\", i_top_10)\n",
        "print(\"Top 10 words that end with ू:\", u_top_10)\n",
        "print(\"Top 10 words that end with ृ:\", r_top_10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2VDgcprmmOD",
        "outputId": "7d969da2-9fd9-41e6-ed9e-d77845e245c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words that end with ि: 666\n",
            "Number of words that end with ू: 115\n",
            "Number of words that end with ृ: 30\n",
            "Top 10 words that end with ि: ['लि', 'लि', 'लि', 'लि', 'लि', 'लि', 'लि', 'लि', 'लि', 'लि']\n",
            "Top 10 words that end with ू: ['रूप|रू', 'रूप|रू', 'रूप|रू', 'रूप|रू', 'रूप|रू', 'रूप|रू', 'रूप|रू', 'रूप|रू', 'रूप|रू', 'रूप|रू']\n",
            "Top 10 words that end with ृ: ['प्राकृतिक|प्राकृ', 'मृत्यु|मृ', 'प्राकृतिक|प्राकृ', 'मृत्यु|मृ', 'मृत्यु|मृ', 'प्राकृतिक|प्राकृ', 'कृपया|कृ', 'प्रवृत्ति|प्रवृ', 'वृद्धि|वृ', 'प्रवृत्ति|प्रवृ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "with open('1_Tagged_Hindi_Corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "words = nltk.word_tokenize(text)\n",
        "\n",
        "mu_words = [word for word in words if word.startswith('मु')]\n",
        "\n",
        "mu_word_count = len(mu_words)\n",
        "print(\"Total number of words starting with 'मु':\", mu_word_count)\n",
        "\n",
        "if mu_word_count > 0:\n",
        "    freq_dist = nltk.FreqDist(mu_words)\n",
        "    top_10 = freq_dist.most_common(10)\n",
        "    print(\"Top 10 'मु' words and their frequency:\")\n",
        "    for word, freq in top_10:\n",
        "        print(f\"{word}: {freq}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ippvv_yCoDZw",
        "outputId": "66be10ca-4e63-4b38-c12c-04bb0c321f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of words starting with 'मु': 21\n",
            "Top 10 'मु' words and their frequency:\n",
            "मुकदमा|मुकदमा.0|NN.n.m.sg.3.d: 2\n",
            "मुखबिरों|मुखबिर.0|NN.n.m.pl.3.o: 1\n",
            "मुलाकातें|मुलाकात.0|NN.n.f.pl.3.d: 1\n",
            "मुकम्मिल|मुकम्मिल.|JJ.adj.any.any: 1\n",
            "मुझे|मुझे.|PRP.unk: 1\n",
            "मुर्गे|मुर्गा.0|NN.n.m.pl.3.d: 1\n",
            "मुद्राओं|मुद्रा.0|NN.n.f.pl.3.o: 1\n",
            "मुलायम|मुलायम.|XC.adj.any.any: 1\n",
            "मुंह|मुँह.0|NN.n.m.sg: 1\n",
            "मुस्लिम|मुस्लिम.|JJ.unk: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "with open('1_Tagged_Hindi_Corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "words = nltk.word_tokenize(text)\n",
        "\n",
        "hindi_words = [word for word in words if '\\u0900' <= word <= '\\u097f'] \n",
        "\n",
        "freq_dist = nltk.FreqDist(hindi_words)\n",
        "top_15 = freq_dist.most_common(15)\n",
        "\n",
        "print(\"Top 15 most frequent Hindi words in the corpus:\")\n",
        "for word, freq in top_15:\n",
        "    print(f\"{word}: {freq}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n16ZWcogpYMN",
        "outputId": "e1884480-7775-4e86-f279-eff22d2bddb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 15 most frequent Hindi words in the corpus:\n",
            "के|का.का|PSP.psp.m.sg: 218\n",
            "में|में.|PSP.psp: 149\n",
            "की|का.का|PSP.psp.f.sg: 131\n",
            "है|है.है|VAUX.v.any.sg.2: 112\n",
            "और|और.|CC.adv: 105\n",
            "से|से.|PSP.v.any.any.any: 102\n",
            "को|को.|PSP.psp: 87\n",
            "का|का.का|PSP.psp.m.sg: 61\n",
            "हैं|है.है|VAUX.v.any.pl.1: 51\n",
            "कि|कि.|CC.avy: 50\n",
            "पर|पर.|PSP.psp: 48\n",
            "भी|भी.|RP.adv: 46\n",
            "है|है.है|VM.v.any.sg.2: 45\n",
            "नहीं|नहीं.|NEG.adv: 36\n",
            "ही|ही.|RP.adv: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder, TrigramAssocMeasures, TrigramCollocationFinder\n",
        "\n",
        "with open(\"1_Tagged_Hindi_Corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    corpus = f.read()\n",
        "\n",
        "tokens = nltk.word_tokenize(corpus)\n",
        "\n",
        "bigram_measures = BigramAssocMeasures()\n",
        "trigram_measures = TrigramAssocMeasures()\n",
        "\n",
        "bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
        "trigram_finder = TrigramCollocationFinder.from_words(tokens)\n",
        "\n",
        "bigram_finder.apply_freq_filter(5)\n",
        "trigram_finder.apply_freq_filter(5)\n",
        "\n",
        "print(\"Top 5 Bigram Collocations:\")\n",
        "for i, collocation in enumerate(bigram_finder.nbest(bigram_measures.raw_freq, 5)):\n",
        "    print(f\"{i+1}. {' '.join(collocation)}\")\n",
        "\n",
        "print(\"\\nTop 5 Trigram Collocations:\")\n",
        "for i, collocation in enumerate(trigram_finder.nbest(trigram_measures.raw_freq, 5)):\n",
        "    print(f\"{i+1}. {' '.join(collocation)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj9ejui7wc6H",
        "outputId": "f186ab41-0359-4f43-be8e-80b621b0f476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Bigram Collocations:\n",
            "1. .. any\n",
            "2. .. d\n",
            "3. .. o\n",
            "4. .. |SYM.punc\n",
            "5. .| ..\n",
            "\n",
            "Top 5 Trigram Collocations:\n",
            "1. .. |SYM.punc ....\n",
            "2. .| .. |SYM.punc\n",
            "3. के|का.का|PSP.psp.m.sg .. o\n",
            "4. . .| ..\n",
            "5. की|का.का|PSP.psp.f.sg .. d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning\n"
      ],
      "metadata": {
        "id": "dyHxi2630OPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Learning\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "import re\n",
        "\n",
        "# read the text file\n",
        "with open('hindi_text_cleaned.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "import numpy as np\n",
        "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
        "    for _ in range(n_words):\n",
        "        encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, truncating='pre')\n",
        "        # predict probabilities for each word\n",
        "        yhat_probs = model.predict(encoded, verbose=0)\n",
        "        # convert probabilities to integer indices\n",
        "        yhat = np.argmax(yhat_probs, axis=-1)\n",
        "        # map predicted word index to word\n",
        "        out_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == yhat:\n",
        "                out_word = word\n",
        "                break\n",
        "        # append to input sequence\n",
        "        seed_text += ' ' + out_word\n",
        "    return seed_text\n"
      ],
      "metadata": {
        "id": "8mFdLQ2twYGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "encoded = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUgGc1pf0E7C",
        "outputId": "c9c5214f-f1cb-40a0-b8f6-a42a2223f5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[301, 1, 569, 570, 20, 18, 571, 9, 572, 25, 14, 41, 573, 4, 199, 6, 54, 124, 574, 125, 126, 302, 13, 575, 19, 576, 10, 55, 303, 577, 9, 578, 19, 304, 8, 56, 103, 7, 579, 305, 306, 307, 580, 1, 160, 11, 308, 309, 45, 310, 3, 311, 1, 581, 582, 312, 200, 201, 34, 202, 583, 313, 203, 314, 204, 315, 31, 584, 69, 316, 87, 88, 585, 317, 75, 11, 318, 46, 1, 319, 9, 127, 26, 9, 320, 14, 21, 16, 321, 1, 586, 1, 76, 57, 58, 322, 587, 77, 128, 588, 6, 35, 129, 8, 589, 1, 590, 591, 1, 592, 1, 205, 13, 321, 593, 3, 594, 47, 2, 595, 20, 596, 6, 323, 36, 206, 597, 4, 207, 598, 208, 25, 10, 29, 48, 12, 70, 6, 51, 130, 209, 599, 324, 43, 2, 23, 325, 3, 210, 326, 1, 69, 57, 1, 76, 600, 601, 7, 602, 69, 4, 211, 325, 11, 35, 603, 604, 6, 605, 26, 4, 327, 2, 606, 1, 161, 21, 6, 35, 607, 328, 212, 317, 42, 89, 8, 5, 54, 327, 7, 329, 1, 608, 4, 609, 3, 610, 19, 59, 37, 2, 213, 611, 162, 612, 330, 2, 27, 131, 16, 613, 162, 9, 614, 2, 27, 615, 71, 616, 7, 90, 19, 49, 2, 5, 18, 72, 91, 7, 24, 331, 3, 214, 4, 332, 12, 73, 2, 78, 5, 1, 72, 1, 60, 617, 1, 60, 43, 618, 619, 1, 17, 620, 163, 44, 333, 334, 15, 61, 2, 104, 132, 335, 105, 8, 5, 104, 132, 24, 621, 215, 3, 131, 622, 216, 19, 623, 59, 40, 8, 624, 33, 334, 2, 27, 336, 625, 36, 626, 1, 627, 6, 164, 628, 3, 165, 629, 337, 630, 4, 631, 632, 46, 5, 337, 633, 106, 634, 34, 635, 46, 107, 62, 2, 636, 637, 338, 339, 133, 638, 639, 5, 38, 3, 217, 20, 24, 79, 340, 640, 9, 134, 25, 5, 24, 218, 4, 341, 1, 17, 641, 135, 4, 642, 643, 4, 11, 136, 55, 644, 7, 35, 63, 342, 219, 40, 8, 30, 55, 18, 63, 1, 645, 75, 1, 56, 137, 646, 647, 15, 19, 89, 29, 648, 220, 221, 4, 649, 343, 1, 92, 3, 12, 336, 222, 40, 18, 650, 651, 3, 166, 9, 652, 167, 48, 108, 4, 64, 343, 1, 205, 80, 26, 4, 166, 653, 12, 654, 3, 655, 656, 17, 71, 657, 4, 658, 659, 344, 90, 660, 6, 661, 8, 662, 52, 35, 80, 19, 61, 2, 168, 207, 169, 72, 138, 663, 6, 81, 28, 6, 345, 6, 139, 223, 3, 82, 77, 664, 3, 140, 665, 224, 23, 93, 82, 170, 666, 1, 160, 11, 79, 667, 83, 668, 23, 346, 344, 347, 348, 92, 3, 55, 50, 349, 347, 669, 670, 671, 171, 350, 672, 673, 674, 6, 675, 676, 2, 677, 678, 5, 679, 680, 681, 351, 682, 4, 683, 3, 352, 20, 52, 7, 684, 125, 10, 136, 353, 354, 685, 4, 30, 355, 686, 687, 225, 356, 3, 13, 141, 357, 2, 10, 688, 7, 139, 689, 1, 84, 319, 9, 690, 85, 65, 5, 358, 4, 359, 360, 71, 361, 1, 205, 127, 342, 65, 691, 20, 142, 16, 21, 692, 693, 33, 39, 226, 6, 694, 362, 695, 3, 696, 697, 698, 169, 363, 699, 5, 700, 701, 1, 72, 172, 702, 16, 2, 5, 94, 1, 364, 227, 1, 703, 704, 9, 705, 706, 707, 2, 365, 1, 228, 4, 81, 708, 1, 76, 229, 91, 3, 109, 173, 709, 73, 2, 366, 710, 46, 74, 711, 4, 712, 367, 713, 73, 2, 27, 714, 715, 2, 77, 230, 7, 24, 110, 1, 231, 716, 717, 15, 47, 14, 718, 354, 1, 38, 368, 232, 6, 174, 9, 21, 719, 369, 720, 14, 18, 370, 3, 143, 721, 722, 6, 723, 371, 95, 30, 144, 222, 10, 53, 3, 96, 724, 82, 8, 27, 175, 6, 172, 35, 129, 8, 18, 233, 7, 320, 2, 10, 33, 372, 373, 36, 234, 11, 725, 19, 111, 2, 145, 374, 3, 726, 1, 727, 1, 28, 3, 728, 7, 229, 70, 4, 729, 3, 375, 111, 2, 31, 376, 730, 731, 6, 732, 377, 3, 235, 2, 34, 733, 9, 734, 106, 735, 9, 736, 12, 737, 28, 6, 47, 2, 176, 738, 47, 2, 10, 77, 739, 1, 740, 57, 58, 741, 742, 743, 1, 744, 7, 236, 745, 26, 58, 43, 225, 41, 378, 13, 146, 46, 746, 2, 31, 77, 747, 4, 237, 379, 52, 88, 4, 62, 2, 5, 66, 24, 237, 380, 3, 748, 177, 1, 17, 381, 749, 40, 8, 11, 13, 177, 307, 60, 6, 35, 15, 22, 111, 24, 234, 7, 750, 67, 6, 382, 97, 1, 17, 751, 7, 50, 752, 31, 23, 753, 86, 238, 383, 7, 754, 305, 384, 239, 8, 31, 5, 755, 3, 385, 1, 756, 757, 4, 386, 387, 758, 7, 759, 760, 385, 761, 1, 762, 4, 86, 763, 16, 73, 61, 8, 110, 23, 15, 147, 2, 96, 764, 6, 765, 766, 27, 48, 388, 1, 767, 7, 240, 241, 4, 389, 148, 147, 768, 390, 769, 242, 87, 145, 165, 242, 87, 112, 37, 2, 66, 770, 94, 69, 1, 87, 113, 8, 771, 18, 232, 6, 391, 75, 772, 10, 392, 773, 393, 394, 774, 5, 395, 6, 396, 775, 22, 243, 776, 777, 97, 6, 56, 397, 7, 778, 244, 779, 62, 2, 398, 780, 9, 781, 114, 1, 782, 783, 784, 242, 1, 103, 785, 38, 12, 786, 4, 399, 787, 178, 146, 46, 788, 3, 15, 789, 245, 790, 10, 77, 791, 7, 246, 50, 26, 9, 792, 3, 44, 400, 15, 2, 149, 793, 1, 92, 3, 112, 37, 2, 10, 66, 794, 6, 371, 126, 8, 41, 66, 795, 796, 15, 66, 797, 8, 66, 179, 15, 8, 5, 172, 172, 6, 30, 44, 798, 12, 15, 799, 8, 401, 57, 3, 800, 801, 36, 401, 50, 22, 802, 803, 98, 804, 383, 3, 128, 805, 11, 150, 37, 2, 169, 76, 402, 9, 134, 806, 28, 3, 807, 39, 808, 28, 809, 22, 239, 8, 29, 810, 28, 8, 27, 811, 812, 67, 6, 813, 22, 83, 8, 10, 24, 814, 815, 1, 403, 816, 28, 6, 75, 9, 50, 30, 247, 40, 8, 5, 50, 42, 16, 89, 8, 41, 404, 12, 139, 817, 18, 818, 11, 146, 248, 151, 68, 78, 3, 405, 369, 115, 14, 27, 146, 406, 16, 14, 819, 393, 820, 821, 1, 174, 3, 407, 22, 61, 68, 822, 408, 180, 90, 22, 116, 14, 136, 132, 823, 30, 64, 51, 824, 409, 7, 117, 11, 825, 826, 89, 32, 827, 7, 828, 5, 48, 12, 829, 399, 1, 830, 3, 13, 831, 15, 32, 410, 17, 179, 5, 411, 412, 4, 413, 414, 249, 65, 415, 832, 5, 833, 1, 416, 3, 181, 9, 834, 2, 5, 13, 51, 835, 117, 180, 1, 836, 16, 20, 837, 2, 52, 20, 118, 174, 9, 417, 838, 839, 5, 93, 840, 1, 28, 3, 107, 250, 24, 251, 1, 841, 1, 418, 842, 7, 23, 419, 843, 844, 420, 29, 252, 3, 845, 90, 5, 846, 34, 847, 848, 35, 32, 23, 421, 411, 182, 3, 253, 8, 5, 849, 7, 422, 8, 99, 23, 421, 93, 850, 182, 3, 253, 8, 5, 851, 7, 422, 8, 423, 201, 852, 3, 13, 112, 45, 2, 10, 424, 48, 12, 70, 1, 853, 7, 854, 25, 243, 30, 855, 33, 856, 152, 37, 2, 27, 38, 3, 857, 22, 37, 2, 858, 4, 859, 860, 861, 46, 862, 254, 4, 863, 9, 76, 864, 61, 865, 183, 1, 866, 867, 3, 149, 140, 425, 11, 868, 255, 184, 2, 426, 357, 364, 869, 425, 1, 427, 11, 25, 45, 2, 870, 428, 871, 872, 4, 429, 4, 873, 362, 125, 42, 61, 2, 39, 874, 3, 18, 134, 119, 1, 430, 875, 8, 5, 256, 431, 876, 4, 877, 4, 878, 2, 257, 879, 7, 39, 221, 1, 38, 880, 432, 3, 881, 257, 882, 883, 6, 884, 62, 2, 168, 433, 885, 26, 6, 56, 23, 63, 1, 17, 98, 886, 887, 374, 375, 59, 45, 14, 153, 39, 888, 12, 32, 120, 72, 889, 258, 5, 217, 1, 72, 3, 890, 891, 147, 11, 892, 82, 64, 893, 11, 236, 894, 22, 83, 31, 434, 1, 259, 1, 131, 6, 895, 435, 3, 417, 57, 1, 896, 897, 142, 16, 113, 8, 121, 13, 898, 16, 14, 10, 29, 260, 899, 4, 900, 9, 436, 40, 437, 438, 20, 901, 7, 352, 5, 230, 6, 902, 903, 904, 5, 437, 905, 1, 906, 3, 907, 3, 439, 4, 136, 55, 440, 7, 908, 909, 910, 19, 89, 8, 30, 29, 38, 3, 911, 232, 6, 912, 5, 39, 215, 3, 913, 914, 915, 167, 168, 39, 916, 917, 918, 919, 441, 3, 920, 442, 2, 41, 921, 333, 2, 443, 177, 1, 38, 922, 923, 13, 924, 444, 25, 42, 49, 2, 353, 64, 165, 154, 171, 1, 925, 6, 24, 445, 446, 4, 926, 4, 447, 33, 445, 135, 4, 261, 6, 164, 22, 448, 41, 117, 11, 927, 9, 928, 185, 929, 449, 14, 79, 11, 93, 450, 91, 4, 12, 930, 34, 931, 4, 229, 932, 8, 153, 11, 933, 934, 935, 8, 316, 936, 937, 1, 28, 3, 82, 938, 8, 939, 451, 9, 21, 35, 355, 940, 2, 941, 942, 3, 943, 944, 7, 57, 151, 945, 946, 91, 9, 947, 2, 10, 74, 96, 48, 100, 3, 214, 4, 332, 15, 2, 262, 33, 244, 15, 948, 104, 33, 949, 3, 950, 2, 36, 153, 951, 952, 58, 953, 15, 954, 955, 5, 956, 80, 452, 60, 957, 5, 958, 1, 17, 5, 84, 3, 93, 959, 3, 163, 960, 453, 75, 58, 961, 80, 13, 454, 455, 4, 211, 35, 456, 5, 962, 2, 5, 963, 454, 455, 7, 263, 19, 59, 2, 443, 186, 964, 6, 12, 965, 966, 967, 453, 75, 4, 968, 253, 2, 969, 3, 171, 20, 970, 1, 63, 4, 67, 230, 7, 24, 971, 3, 457, 1, 231, 972, 26, 9, 973, 25, 155, 39, 458, 974, 30, 975, 16, 41, 23, 1, 84, 976, 977, 459, 12, 187, 224, 6, 978, 103, 460, 1, 101, 8, 979, 980, 5, 981, 982, 18, 461, 983, 1, 984, 32, 264, 186, 985, 986, 462, 265, 987, 266, 4, 463, 6, 988, 3, 989, 990, 991, 4, 267, 4, 68, 52, 146, 13, 464, 15, 19, 992, 2, 10, 268, 465, 3, 214, 58, 993, 994, 164, 995, 996, 118, 84, 21, 997, 370, 208, 148, 2, 5, 18, 92, 3, 64, 998, 3, 269, 6, 999, 1000, 2, 29, 1001, 4, 128, 1002, 6, 1003, 40, 43, 79, 46, 10, 1004, 394, 1005, 1006, 1007, 20, 12, 54, 1008, 5, 1009, 3, 1010, 246, 25, 86, 1011, 5, 183, 6, 132, 131, 444, 15, 42, 89, 18, 431, 3, 397, 7, 1012, 1013, 466, 112, 37, 2, 109, 1014, 38, 16, 1015, 1016, 20, 98, 24, 79, 1017, 1, 17, 1018, 25, 1019, 1, 467, 416, 6, 56, 419, 119, 11, 12, 1020, 1021, 361, 1022, 4, 62, 68, 41, 171, 20, 137, 245, 468, 4, 1023, 4, 1024, 11, 188, 469, 6, 164, 12, 270, 6, 470, 4, 62, 2, 10, 29, 24, 381, 4, 1025, 1, 1026, 1027, 9, 326, 391, 1028, 29, 1029, 4, 1030, 11, 12, 1031, 5, 1032, 1033, 1034, 471, 10, 18, 1035, 1036, 7, 5, 12, 1037, 73, 11, 55, 271, 16, 53, 248, 4, 15, 1038, 38, 1, 1039, 181, 1, 472, 472, 13, 1040, 22, 126, 23, 120, 1041, 4, 1042, 1043, 105, 8, 30, 23, 120, 1044, 31, 359, 1, 23, 1045, 12, 27, 100, 1, 170, 473, 1, 32, 155, 220, 221, 1, 17, 34, 24, 72, 474, 26, 1, 17, 1046, 71, 32, 144, 52, 6, 39, 449, 3, 135, 3, 475, 26, 5, 220, 23, 476, 1047, 26, 9, 1048, 25, 1049, 1050, 250, 41, 96, 1051, 1052, 6, 378, 51, 4, 42, 61, 2, 104, 409, 20, 1053, 3, 137, 1054, 1055, 1, 17, 188, 2, 44, 21, 108, 120, 216, 1056, 2, 5, 33, 12, 86, 1057, 477, 15, 478, 20, 479, 188, 10, 217, 6, 1058, 218, 1, 115, 9, 154, 480, 1, 88, 1059, 218, 6, 1060, 1061, 14, 121, 44, 12, 133, 258, 6, 122, 15, 22, 49, 5, 50, 16, 64, 1062, 6, 102, 4, 210, 1063, 3, 272, 24, 133, 180, 3, 123, 19, 49, 2, 477, 481, 11, 1064, 26, 4, 1065, 1, 76, 114, 4, 1066, 5, 1067, 189, 5, 257, 28, 107, 1068, 8, 5, 21, 16, 51, 7, 1069, 4, 335, 152, 62, 2, 33, 1070, 9, 127, 482, 19, 49, 14, 99, 1071, 483, 7, 219, 19, 107, 144, 1072, 484, 7, 1073, 25, 36, 273, 6, 1074, 462, 54, 439, 4, 68, 5, 98, 130, 1075, 14, 252, 3, 485, 486, 16, 21, 176, 486, 2, 153, 115, 182, 2, 5, 306, 1076, 2, 190, 70, 274, 77, 1077, 7, 1078, 105, 8, 94, 70, 29, 1079, 1, 1080, 1, 275, 5, 1081, 7, 487, 105, 8, 1082, 1, 1083, 4, 1084, 435, 60, 73, 2, 18, 1085, 1, 1086, 181, 3, 1087, 1088, 5, 1089, 9, 465, 1090, 37, 14, 408, 6, 82, 7, 81, 1091, 2, 120, 1092, 34, 1093, 1094, 488, 37, 2, 213, 1095, 4, 44, 51, 15, 249, 65, 10, 143, 13, 1096, 147, 30, 118, 489, 7, 94, 1097, 351, 1098, 9, 21, 1099, 1100, 262, 74, 18, 1101, 1, 17, 1102, 125, 95, 68, 1103, 1104, 1, 1105, 7, 1106, 12, 1107, 1108, 2, 1109, 138, 7, 23, 1110, 191, 191, 5, 1111, 56, 7, 23, 1112, 191, 191, 1113, 11, 1114, 1115, 1116, 9, 1117, 30, 410, 1118, 11, 16, 47, 2, 13, 303, 2, 10, 358, 7, 1119, 11, 1120, 1121, 1, 160, 11, 16, 24, 127, 97, 113, 8, 5, 44, 108, 13, 470, 15, 19, 49, 5, 50, 490, 65, 10, 48, 108, 1, 1122, 1123, 83, 483, 7, 1124, 26, 1, 17, 1125, 1126, 50, 22, 30, 12, 69, 74, 1127, 1128, 53, 467, 1129, 1, 161, 1130, 1131, 1, 491, 1132, 3, 1133, 83, 13, 1134, 9, 192, 10, 492, 1135, 3, 62, 2, 13, 47, 2, 10, 492, 7, 493, 494, 4, 463, 1136, 25, 448, 447, 495, 1137, 1138, 493, 494, 26, 4, 1139, 1140, 22, 1141, 1142, 1143, 14, 5, 134, 12, 1144, 1145, 6, 14, 78, 1, 496, 1146, 1147, 4, 341, 3, 407, 6, 115, 173, 60, 4, 156, 6, 187, 78, 9, 60, 1148, 276, 1149, 1150, 4, 277, 1, 76, 1151, 14, 497, 5, 1152, 1153, 1, 231, 1154, 85, 129, 2, 48, 1155, 5, 1156, 487, 3, 1157, 395, 6, 56, 13, 1158, 3, 1159, 1160, 2, 64, 1161, 1, 1162, 1, 1163, 432, 1, 38, 1, 1164, 1165, 157, 86, 1166, 60, 4, 1167, 3, 1168, 4, 278, 22, 95, 1169, 189, 1170, 69, 3, 90, 6, 90, 323, 498, 113, 8, 185, 101, 2, 1171, 21, 176, 101, 27, 175, 1, 17, 413, 1172, 499, 116, 1173, 3, 1174, 1175, 9, 13, 1176, 1177, 500, 7, 1178, 2, 10, 273, 484, 7, 1179, 501, 1180, 404, 56, 52, 7, 64, 279, 438, 1, 1181, 1, 92, 3, 273, 7, 501, 85, 65, 79, 13, 1182, 44, 1183, 15, 167, 10, 280, 206, 1184, 3, 44, 429, 16, 2, 29, 1185, 15, 71, 5, 169, 1, 84, 396, 266, 6, 502, 263, 22, 45, 79, 46, 10, 503, 281, 1186, 3, 143, 1187, 20, 21, 1188, 282, 7, 1189, 25, 30, 29, 1190, 11, 283, 15, 32, 99, 1191, 1192, 155, 1193, 43, 1194, 6, 23, 20, 1195, 1196, 1197, 1, 1198, 6, 53, 3, 1199, 1200, 9, 247, 25, 14, 5, 210, 504, 1, 1201, 6, 16, 284, 1202, 1203, 43, 32, 66, 206, 1204, 1205, 28, 6, 1206, 1207, 239, 8, 27, 274, 505, 1, 193, 1208, 8, 31, 213, 1209, 506, 1210, 68, 433, 3, 507, 265, 508, 1211, 1212, 53, 52, 4, 267, 34, 507, 265, 508, 5, 338, 106, 1213, 1, 72, 1214, 509, 510, 468, 3, 1215, 57, 11, 66, 285, 53, 4, 1216, 1, 1217, 225, 1218, 190, 67, 256, 124, 4, 1219, 94, 124, 4, 16, 67, 73, 2, 5, 1220, 24, 1221, 4, 67, 94, 70, 1222, 26, 58, 1, 226, 1223, 16, 1224, 2, 1225, 1226, 20, 1227, 41, 1228, 3, 120, 190, 70, 222, 45, 2, 511, 13, 1229, 47, 2, 10, 33, 1230, 6, 21, 1231, 6, 35, 1232, 15, 2, 21, 498, 4, 1233, 7, 138, 9, 1234, 1235, 512, 37, 2, 452, 10, 503, 1236, 3, 286, 25, 42, 1237, 2, 23, 87, 1238, 1, 513, 3, 163, 163, 1239, 6, 1240, 23, 514, 40, 8, 1241, 97, 9, 192, 13, 2, 10, 114, 1, 1242, 54, 1243, 34, 39, 270, 4, 1244, 106, 515, 7, 34, 80, 26, 4, 54, 1245, 7, 1246, 150, 42, 516, 5, 29, 287, 48, 1247, 36, 1248, 1, 110, 19, 1249, 451, 1250, 7, 1251, 148, 2, 5, 182, 7, 1252, 1253, 2, 54, 1254, 1, 38, 1255, 1256, 1257, 88, 98, 1258, 1259, 3, 1260, 45, 471, 4, 1261, 1, 1262, 1263, 1264, 1265, 88, 149, 11, 308, 309, 42, 516, 13, 288, 5, 1266, 1267, 1, 128, 1268, 356, 1, 517, 14, 518, 1269, 1270, 11, 1271, 1272, 1273, 1, 285, 5, 103, 5, 1274, 8, 1275, 11, 1276, 5, 1277, 8, 41, 1278, 1279, 3, 21, 1280, 203, 289, 2, 262, 203, 1281, 1, 418, 1282, 34, 1283, 1, 1284, 339, 28, 6, 1285, 1286, 1, 1287, 272, 40, 8, 121, 1288, 28, 6, 33, 290, 1289, 6, 1290, 14, 1291, 1292, 446, 5, 74, 268, 1293, 11, 1294, 4, 519, 1295, 2, 1296, 1297, 1298, 1299, 1300, 520, 8, 5, 98, 1301, 12, 26, 4, 389, 40, 8, 1302, 1303, 4, 1304, 11, 12, 81, 245, 97, 4, 521, 73, 2, 405, 1305, 522, 482, 25, 42, 49, 2, 1306, 20, 102, 282, 3, 112, 14, 10, 291, 292, 6, 485, 1307, 21, 108, 21, 1308, 6, 2, 78, 160, 60, 6, 428, 174, 9, 189, 1309, 78, 3, 46, 140, 45, 13, 479, 188, 45, 14, 10, 78, 3, 158, 1310, 32, 5, 1311, 1312, 1313, 1314, 1, 523, 3, 1315, 71, 32, 18, 1316, 1317, 6, 346, 123, 293, 10, 1318, 1319, 345, 4, 5, 1320, 1321, 147, 424, 21, 6, 35, 1322, 8, 30, 1323, 1324, 7, 21, 1325, 4, 237, 490, 73, 2, 104, 1326, 3, 1327, 57, 4, 277, 3, 1328, 1329, 25, 37, 2, 1330, 27, 524, 1331, 281, 9, 14, 5, 64, 372, 34, 1332, 373, 1333, 1, 84, 235, 14, 31, 41, 290, 525, 143, 1334, 4, 177, 263, 22, 62, 2, 30, 52, 24, 1335, 74, 5, 1336, 9, 1337, 1338, 2, 5, 118, 17, 102, 1, 1339, 1340, 3, 526, 19, 1341, 2, 194, 1342, 9, 69, 193, 1343, 69, 14, 33, 100, 9, 193, 328, 14, 27, 82, 1344, 36, 159, 440, 4, 1345, 40, 2, 66, 1346, 1347, 8, 10, 1348, 11, 1349, 4, 1350, 1, 17, 283, 108, 13, 1351, 4, 277, 3, 32, 10, 98, 1352, 251, 4, 199, 158, 111, 2, 13, 289, 114, 5, 114, 270, 4, 1353, 5, 54, 515, 4, 1354, 26, 3, 129, 367, 1355, 8, 21, 240, 1356, 1, 510, 1357, 251, 1358, 1359, 7, 1360, 4, 1361, 31, 18, 70, 1, 329, 1, 1362, 80, 1363, 1364, 1365, 1, 32, 5, 450, 1366, 39, 80, 3, 475, 15, 40, 32, 1367, 39, 1368, 105, 8, 10, 29, 1369, 8, 5, 271, 7, 130, 1370, 9, 44, 1371, 15, 1372, 27, 1373, 4, 1374, 1, 517, 2, 18, 189, 192, 1, 84, 84, 1375, 269, 9, 1376, 12, 63, 63, 11, 57, 151, 81, 1377, 1378, 6, 1379, 1, 192, 6, 116, 2, 388, 7, 275, 1, 1380, 3, 1381, 67, 1382, 5, 1383, 74, 1384, 1385, 1386, 31, 118, 17, 13, 139, 1387, 68, 104, 1388, 1389, 85, 16, 1390, 1, 403, 1391, 1, 17, 107, 1392, 45, 1393, 1, 1394, 3, 13, 123, 511, 1395, 151, 124, 4, 1396, 7, 1397, 49, 2, 5, 18, 67, 122, 122, 70, 4, 1398, 124, 1399, 42, 111, 2, 13, 86, 18, 51, 11, 527, 209, 148, 10, 55, 294, 1400, 3, 528, 9, 259, 19, 43, 2, 13, 18, 11, 12, 527, 148, 2, 10, 275, 254, 3, 294, 525, 528, 9, 259, 19, 43, 2, 1401, 529, 186, 350, 24, 1402, 3, 1403, 9, 80, 226, 3, 107, 116, 2, 77, 1404, 4, 1405, 246, 22, 75, 46, 137, 110, 530, 50, 26, 7, 21, 1406, 1407, 1408, 105, 144, 121, 402, 34, 1409, 3, 322, 123, 1410, 531, 1411, 1, 1412, 4, 199, 532, 1, 247, 1413, 255, 1414, 488, 1415, 533, 349, 8, 10, 29, 271, 117, 52, 3, 110, 19, 43, 8, 1416, 279, 534, 4, 119, 162, 125, 2, 159, 12, 29, 1417, 5, 1418, 134, 156, 4, 51, 40, 8, 365, 7, 153, 150, 243, 117, 1419, 6, 412, 1420, 4, 12, 1421, 406, 414, 249, 65, 53, 3, 1422, 1423, 3, 1424, 5, 460, 4, 535, 122, 122, 68, 1425, 13, 141, 15, 2, 10, 294, 1426, 24, 1427, 6, 536, 1428, 33, 1429, 14, 10, 185, 1430, 63, 140, 45, 2, 33, 1431, 1432, 12, 14, 1433, 274, 505, 1, 423, 1434, 1435, 9, 101, 2, 31, 1436, 39, 1437, 9, 537, 538, 442, 295, 1438, 2, 18, 1439, 119, 1, 1440, 1441, 469, 1, 1442, 1443, 75, 1, 17, 195, 22, 1444, 2, 1445, 145, 1446, 1, 441, 1, 1447, 12, 1448, 113, 32, 5, 1449, 1, 1450, 142, 32, 155, 21, 281, 46, 382, 1, 38, 1451, 18, 51, 7, 219, 313, 1452, 227, 293, 10, 1453, 284, 539, 100, 1, 17, 1454, 2, 5, 1455, 9, 1456, 26, 1, 17, 91, 7, 1457, 28, 6, 195, 85, 184, 2, 154, 1458, 196, 456, 14, 420, 518, 1459, 7, 520, 71, 13, 35, 1460, 15, 14, 99, 196, 506, 158, 7, 44, 81, 1461, 15, 1462, 540, 158, 20, 181, 3, 16, 64, 1463, 7, 1464, 19, 250, 5, 38, 4, 103, 480, 20, 86, 1465, 16, 1466, 261, 145, 258, 261, 3, 296, 8, 348, 92, 3, 86, 114, 16, 541, 499, 49, 2, 112, 42, 49, 2, 10, 291, 292, 3, 542, 1, 1467, 4, 1468, 11, 35, 1469, 59, 37, 2, 99, 1470, 292, 3, 1471, 542, 1, 1472, 7, 35, 400, 59, 37, 2, 13, 1473, 184, 2, 15, 30, 1474, 1475, 152, 1476, 33, 500, 1, 1477, 1, 17, 1478, 543, 1479, 9, 1480, 19, 61, 2, 18, 102, 282, 1, 17, 491, 9, 1481, 195, 26, 1, 17, 297, 1, 1482, 4, 21, 1483, 1484, 1485, 65, 1486, 3, 544, 9, 1487, 28, 1488, 1489, 1490, 1491, 2, 363, 1492, 1493, 1494, 1495, 1496, 1, 101, 6, 8, 5, 23, 1497, 36, 544, 1, 101, 6, 23, 1498, 96, 12, 8, 27, 1499, 1500, 244, 545, 3, 5, 1501, 1502, 3, 12, 1503, 40, 8, 1504, 1505, 1506, 1, 196, 340, 1507, 3, 6, 21, 14, 31, 238, 298, 7, 1508, 1509, 4, 1510, 241, 58, 1511, 11, 162, 538, 36, 39, 1512, 3, 248, 11, 1513, 377, 255, 179, 228, 4, 546, 3, 287, 179, 25, 228, 35, 1514, 1515, 22, 37, 2, 48, 12, 1516, 81, 28, 6, 1517, 7, 170, 286, 1518, 1519, 1520, 2, 159, 12, 143, 103, 170, 286, 1521, 145, 1522, 1, 72, 547, 1523, 37, 2, 30, 117, 547, 1, 1524, 392, 57, 9, 548, 235, 2, 1525, 1526, 549, 4, 21, 1527, 1528, 3, 212, 4, 95, 55, 20, 1529, 457, 1530, 26, 6, 56, 1531, 44, 12, 1532, 466, 110, 209, 25, 22, 41, 109, 1533, 138, 100, 1534, 1535, 9, 1536, 15, 360, 1537, 16, 13, 96, 240, 1538, 157, 1539, 22, 95, 27, 1540, 227, 1, 1541, 481, 7, 379, 14, 311, 157, 131, 1542, 6, 312, 200, 201, 1543, 1544, 14, 1545, 5, 368, 1546, 1547, 5, 1548, 157, 298, 314, 1549, 32, 31, 1550, 16, 13, 1551, 53, 12, 140, 1552, 5, 100, 254, 3, 1553, 550, 9, 296, 152, 126, 551, 1554, 4, 552, 1555, 9, 1556, 1557, 531, 1558, 553, 398, 4, 1559, 178, 1560, 1, 1561, 1562, 5, 175, 1, 298, 1, 173, 54, 1563, 1, 1564, 1565, 1566, 61, 1567, 16, 1568, 12, 61, 554, 52, 1, 1569, 1570, 1571, 6, 13, 1572, 1573, 1574, 1575, 6, 1576, 2, 509, 1577, 6, 4, 555, 497, 1578, 3, 299, 91, 4, 278, 187, 68, 176, 1579, 47, 2, 10, 202, 291, 1580, 1, 23, 129, 1581, 142, 1582, 550, 5, 556, 88, 127, 524, 12, 204, 32, 557, 1583, 1, 539, 1, 1584, 535, 3, 284, 5, 279, 1585, 1586, 95, 2, 1587, 300, 558, 1588, 11, 1589, 548, 1590, 1591, 2, 99, 39, 1592, 1593, 1594, 4, 546, 3, 366, 90, 43, 8, 121, 136, 1595, 1, 380, 36, 295, 1596, 1, 92, 3, 238, 44, 559, 8, 30, 197, 233, 1, 1597, 6, 502, 85, 65, 1598, 1599, 2, 10, 297, 100, 5, 387, 534, 1, 513, 3, 1600, 1601, 184, 2, 197, 149, 139, 1602, 1, 17, 24, 7, 195, 85, 167, 27, 130, 1603, 197, 109, 38, 464, 85, 65, 10, 280, 197, 196, 1604, 1605, 158, 116, 2, 36, 15, 31, 66, 559, 18, 180, 1, 17, 1606, 8, 560, 1607, 1, 138, 300, 3, 29, 1608, 22, 1609, 8, 82, 27, 234, 4, 1610, 19, 43, 2, 560, 21, 36, 159, 285, 1611, 4, 278, 22, 126, 2, 1612, 1613, 18, 119, 7, 269, 6, 1614, 8, 168, 1615, 97, 4, 1616, 149, 1617, 9, 1618, 47, 2, 426, 522, 1619, 1620, 1621, 1, 1622, 1, 17, 25, 37, 2, 207, 1623, 16, 33, 1624, 83, 10, 33, 1625, 1, 1626, 152, 83, 2, 121, 1627, 1628, 1629, 5, 1630, 7, 1631, 1, 93, 1632, 7, 122, 15, 150, 42, 49, 109, 1633, 1634, 1, 268, 561, 315, 331, 1, 1635, 1, 17, 1636, 1637, 1, 1638, 1639, 3, 1640, 1641, 212, 25, 1642, 20, 133, 7, 430, 473, 3, 1643, 256, 7, 21, 543, 50, 533, 1, 1644, 19, 59, 2, 102, 1645, 289, 34, 193, 69, 20, 18, 7, 1646, 102, 512, 2, 1647, 1648, 157, 1649, 2, 31, 132, 155, 23, 16, 1650, 1, 215, 4, 211, 19, 89, 8, 1651, 529, 264, 1652, 4, 233, 3, 55, 11, 1653, 12, 19, 111, 2, 1654, 1655, 1656, 133, 264, 1657, 1658, 1659, 186, 194, 3, 18, 51, 7, 141, 19, 59, 45, 2, 10, 194, 5, 1, 161, 562, 563, 4, 267, 36, 39, 1660, 5, 204, 563, 1, 1661, 300, 5, 54, 1662, 545, 3, 123, 1, 17, 1663, 95, 1664, 194, 1, 161, 102, 1, 526, 15, 1665, 1666, 1667, 390, 287, 48, 81, 119, 1, 34, 48, 12, 93, 260, 541, 4, 67, 260, 556, 88, 1668, 25, 42, 49, 2, 1669, 3, 165, 1670, 1671, 1672, 4, 223, 299, 94, 156, 6, 1673, 564, 2, 190, 156, 6, 1674, 1675, 4, 1676, 22, 27, 1677, 1, 63, 283, 223, 4, 299, 115, 1678, 62, 2, 386, 523, 1679, 28, 6, 376, 5, 1680, 47, 2, 1681, 24, 552, 7, 1682, 4, 67, 1683, 5, 1684, 1685, 71, 1686, 1687, 7, 56, 21, 276, 5, 159, 540, 276, 564, 2, 555, 1688, 1, 536, 1689, 1690, 1691, 489, 1692, 1693, 8, 1694, 20, 1695, 178, 7, 1696, 1, 1697, 1698, 7, 558, 301, 1699, 3, 1700, 4, 1701, 97, 5, 74, 1702, 28, 3, 50, 1703, 4, 1704, 1705, 4, 1706, 1, 38, 12, 144, 109, 1707, 3, 1708, 532, 6, 1709, 19, 59, 5, 79, 1710, 4, 519, 1711, 43, 1712, 4, 1713, 87, 1714, 5, 87, 1715, 20, 4, 53, 60, 288, 183, 6, 21, 562, 1716, 1, 530, 1, 458, 96, 16, 63, 3, 6, 1717, 116, 14, 290, 1718, 9, 137, 1719, 47, 2, 5, 434, 9, 436, 26, 1, 118, 1720, 76, 12, 113, 8, 310, 1, 1721, 6, 537, 1722, 2, 10, 1723, 9, 200, 198, 135, 3, 551, 198, 1, 101, 6, 565, 58, 1724, 198, 1, 1725, 236, 1726, 2, 1727, 173, 1728, 318, 4, 156, 6, 565, 58, 18, 198, 20, 115, 154, 135, 11, 1729, 19, 150, 2, 13, 1730, 296, 3, 2, 130, 280, 47, 2, 142, 514, 1731, 1732, 7, 24, 1733, 3, 1734, 7, 1735, 55, 18, 4, 1736, 553, 10, 29, 27, 1737, 304, 8, 29, 252, 3, 74, 216, 324, 43, 8, 36, 15, 175, 476, 427, 11, 202, 8, 99, 1738, 178, 1739, 63, 1, 1740, 1741, 1742, 1743, 8, 302, 1744, 1745, 11, 384, 1746, 26, 151, 1747, 6, 1748, 1749, 1750, 31, 78, 1, 38, 1751, 3, 1752, 293, 41, 1753, 1754, 4, 1755, 459, 241, 1, 17, 1756, 478, 7, 1757, 3, 1758, 123, 4, 521, 208, 187, 1759, 1, 1760, 1, 1761, 1762, 28, 6, 1763, 11, 561, 83, 8, 36, 1764, 28, 6, 1765, 8, 5, 224, 6, 23, 11, 1766, 141, 1767, 1768, 1769, 8, 13, 1770, 566, 27, 10, 1771, 504, 1, 496, 1772, 20, 24, 17, 272, 25, 14, 554, 53, 3, 295, 567, 106, 568, 34, 154, 288, 183, 4, 567, 106, 568, 1, 557, 1773, 11, 1774, 14, 415, 549, 1, 474, 3, 1775, 20, 1776, 1, 1777, 1778, 31, 166, 4, 51, 40, 71, 266, 20, 141, 19, 59, 14, 10, 185, 461, 566, 53, 1, 128, 91, 4, 166, 2, 5, 495, 1779, 4, 297, 12, 330, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary size (total unique words)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: ', vocab_size)\n",
        "sequences = list()\n",
        "for i in range(2, len(encoded)):\n",
        "\tsequence = encoded[i-2:i+1]\n",
        "\tsequences.append(sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a17XHvI0ORW",
        "outputId": "54cd28ec-a0d3-494d-fbc8-8f5791e85326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size:  1780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total Sequences: %d' % len(sequences))\n",
        "# pad sequences\n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
        "print('Max Sequence Length:', max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLC0I-nv0WDS",
        "outputId": "02bf56bb-8ffa-437f-a6e4-d30d371c5368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sequences: 4983\n",
            "Max Sequence Length: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split into input and output elements\n",
        "sequences = array(sequences)\n",
        "X, y = sequences[:,:-1],sequences[:,-1]\n",
        "\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "# define model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "# compile network\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model.fit(X_train, y_train, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQG073C20ZVW",
        "outputId": "4b89312e-761d-47ca-a204-50fcc9d2f838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 2, 10)             17800     \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 50)                12200     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1780)              90780     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120,780\n",
            "Trainable params: 120,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "125/125 - 3s - loss: 7.3160 - accuracy: 0.0409 - 3s/epoch - 25ms/step\n",
            "Epoch 2/200\n",
            "125/125 - 1s - loss: 6.4326 - accuracy: 0.0442 - 814ms/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "125/125 - 1s - loss: 6.2847 - accuracy: 0.0442 - 742ms/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "125/125 - 1s - loss: 6.2179 - accuracy: 0.0442 - 743ms/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "125/125 - 1s - loss: 6.1666 - accuracy: 0.0429 - 756ms/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "125/125 - 1s - loss: 6.1246 - accuracy: 0.0442 - 763ms/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "125/125 - 1s - loss: 6.0937 - accuracy: 0.0432 - 750ms/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "125/125 - 1s - loss: 6.0712 - accuracy: 0.0444 - 767ms/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "125/125 - 1s - loss: 6.0484 - accuracy: 0.0442 - 1s/epoch - 10ms/step\n",
            "Epoch 10/200\n",
            "125/125 - 1s - loss: 6.0287 - accuracy: 0.0444 - 1s/epoch - 10ms/step\n",
            "Epoch 11/200\n",
            "125/125 - 1s - loss: 6.0062 - accuracy: 0.0449 - 879ms/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "125/125 - 1s - loss: 5.9830 - accuracy: 0.0442 - 754ms/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "125/125 - 1s - loss: 5.9585 - accuracy: 0.0449 - 751ms/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "125/125 - 1s - loss: 5.9279 - accuracy: 0.0442 - 767ms/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "125/125 - 1s - loss: 5.8881 - accuracy: 0.0439 - 768ms/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "125/125 - 1s - loss: 5.8482 - accuracy: 0.0447 - 754ms/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "125/125 - 1s - loss: 5.8028 - accuracy: 0.0449 - 793ms/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "125/125 - 1s - loss: 5.7597 - accuracy: 0.0447 - 792ms/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "125/125 - 1s - loss: 5.7174 - accuracy: 0.0449 - 797ms/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "125/125 - 1s - loss: 5.6771 - accuracy: 0.0444 - 776ms/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "125/125 - 1s - loss: 5.6339 - accuracy: 0.0444 - 755ms/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "125/125 - 1s - loss: 5.5885 - accuracy: 0.0464 - 802ms/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "125/125 - 1s - loss: 5.5380 - accuracy: 0.0479 - 807ms/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "125/125 - 1s - loss: 5.4858 - accuracy: 0.0517 - 1s/epoch - 10ms/step\n",
            "Epoch 25/200\n",
            "125/125 - 1s - loss: 5.4294 - accuracy: 0.0517 - 1s/epoch - 11ms/step\n",
            "Epoch 26/200\n",
            "125/125 - 1s - loss: 5.3725 - accuracy: 0.0544 - 803ms/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "125/125 - 1s - loss: 5.3131 - accuracy: 0.0582 - 786ms/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "125/125 - 1s - loss: 5.2546 - accuracy: 0.0607 - 771ms/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "125/125 - 1s - loss: 5.1943 - accuracy: 0.0657 - 764ms/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "125/125 - 1s - loss: 5.1340 - accuracy: 0.0715 - 750ms/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "125/125 - 1s - loss: 5.0717 - accuracy: 0.0745 - 762ms/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "125/125 - 1s - loss: 5.0085 - accuracy: 0.0758 - 775ms/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "125/125 - 1s - loss: 4.9454 - accuracy: 0.0825 - 776ms/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "125/125 - 1s - loss: 4.8848 - accuracy: 0.0871 - 776ms/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "125/125 - 1s - loss: 4.8238 - accuracy: 0.0906 - 1s/epoch - 9ms/step\n",
            "Epoch 36/200\n",
            "125/125 - 1s - loss: 4.7651 - accuracy: 0.0926 - 787ms/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "125/125 - 1s - loss: 4.7096 - accuracy: 0.1011 - 744ms/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "125/125 - 1s - loss: 4.6547 - accuracy: 0.1051 - 1s/epoch - 9ms/step\n",
            "Epoch 39/200\n",
            "125/125 - 1s - loss: 4.5996 - accuracy: 0.1116 - 1s/epoch - 10ms/step\n",
            "Epoch 40/200\n",
            "125/125 - 1s - loss: 4.5475 - accuracy: 0.1094 - 978ms/epoch - 8ms/step\n",
            "Epoch 41/200\n",
            "125/125 - 1s - loss: 4.4977 - accuracy: 0.1177 - 749ms/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "125/125 - 1s - loss: 4.4480 - accuracy: 0.1204 - 809ms/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "125/125 - 1s - loss: 4.4001 - accuracy: 0.1237 - 731ms/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "125/125 - 1s - loss: 4.3499 - accuracy: 0.1279 - 929ms/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "125/125 - 1s - loss: 4.3054 - accuracy: 0.1290 - 778ms/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "125/125 - 1s - loss: 4.2599 - accuracy: 0.1367 - 757ms/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "125/125 - 1s - loss: 4.2137 - accuracy: 0.1443 - 797ms/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "125/125 - 1s - loss: 4.1690 - accuracy: 0.1440 - 744ms/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "125/125 - 1s - loss: 4.1276 - accuracy: 0.1513 - 741ms/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "125/125 - 1s - loss: 4.0811 - accuracy: 0.1535 - 774ms/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "125/125 - 1s - loss: 4.0379 - accuracy: 0.1596 - 792ms/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "125/125 - 1s - loss: 3.9958 - accuracy: 0.1666 - 1s/epoch - 10ms/step\n",
            "Epoch 53/200\n",
            "125/125 - 2s - loss: 3.9544 - accuracy: 0.1781 - 2s/epoch - 15ms/step\n",
            "Epoch 54/200\n",
            "125/125 - 1s - loss: 3.9112 - accuracy: 0.1784 - 1s/epoch - 12ms/step\n",
            "Epoch 55/200\n",
            "125/125 - 1s - loss: 3.8709 - accuracy: 0.1839 - 958ms/epoch - 8ms/step\n",
            "Epoch 56/200\n",
            "125/125 - 1s - loss: 3.8289 - accuracy: 0.1902 - 770ms/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "125/125 - 1s - loss: 3.7884 - accuracy: 0.1932 - 734ms/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "125/125 - 1s - loss: 3.7491 - accuracy: 0.2045 - 843ms/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "125/125 - 1s - loss: 3.7089 - accuracy: 0.2137 - 813ms/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "125/125 - 1s - loss: 3.6699 - accuracy: 0.2215 - 771ms/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "125/125 - 1s - loss: 3.6309 - accuracy: 0.2220 - 1s/epoch - 10ms/step\n",
            "Epoch 62/200\n",
            "125/125 - 1s - loss: 3.5927 - accuracy: 0.2308 - 1s/epoch - 10ms/step\n",
            "Epoch 63/200\n",
            "125/125 - 1s - loss: 3.5559 - accuracy: 0.2444 - 1s/epoch - 9ms/step\n",
            "Epoch 64/200\n",
            "125/125 - 1s - loss: 3.5163 - accuracy: 0.2461 - 1s/epoch - 11ms/step\n",
            "Epoch 65/200\n",
            "125/125 - 2s - loss: 3.4788 - accuracy: 0.2592 - 2s/epoch - 14ms/step\n",
            "Epoch 66/200\n",
            "125/125 - 2s - loss: 3.4392 - accuracy: 0.2599 - 2s/epoch - 12ms/step\n",
            "Epoch 67/200\n",
            "125/125 - 1s - loss: 3.4031 - accuracy: 0.2654 - 1s/epoch - 11ms/step\n",
            "Epoch 68/200\n",
            "125/125 - 1s - loss: 3.3653 - accuracy: 0.2790 - 773ms/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "125/125 - 1s - loss: 3.3300 - accuracy: 0.2802 - 927ms/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "125/125 - 1s - loss: 3.2930 - accuracy: 0.2908 - 1s/epoch - 9ms/step\n",
            "Epoch 71/200\n",
            "125/125 - 1s - loss: 3.2591 - accuracy: 0.2980 - 783ms/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "125/125 - 1s - loss: 3.2229 - accuracy: 0.3073 - 763ms/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "125/125 - 1s - loss: 3.1878 - accuracy: 0.3108 - 751ms/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "125/125 - 1s - loss: 3.1519 - accuracy: 0.3166 - 788ms/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "125/125 - 1s - loss: 3.1147 - accuracy: 0.3249 - 787ms/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "125/125 - 1s - loss: 3.0826 - accuracy: 0.3334 - 1s/epoch - 9ms/step\n",
            "Epoch 77/200\n",
            "125/125 - 1s - loss: 3.0482 - accuracy: 0.3427 - 1s/epoch - 12ms/step\n",
            "Epoch 78/200\n",
            "125/125 - 2s - loss: 3.0100 - accuracy: 0.3485 - 2s/epoch - 12ms/step\n",
            "Epoch 79/200\n",
            "125/125 - 1s - loss: 2.9764 - accuracy: 0.3590 - 935ms/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "125/125 - 1s - loss: 2.9440 - accuracy: 0.3598 - 908ms/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "125/125 - 1s - loss: 2.9116 - accuracy: 0.3733 - 790ms/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "125/125 - 1s - loss: 2.8762 - accuracy: 0.3793 - 782ms/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "125/125 - 1s - loss: 2.8438 - accuracy: 0.3876 - 942ms/epoch - 8ms/step\n",
            "Epoch 84/200\n",
            "125/125 - 1s - loss: 2.8119 - accuracy: 0.3876 - 811ms/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "125/125 - 1s - loss: 2.7795 - accuracy: 0.4034 - 752ms/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "125/125 - 1s - loss: 2.7461 - accuracy: 0.4122 - 777ms/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "125/125 - 1s - loss: 2.7139 - accuracy: 0.4170 - 758ms/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "125/125 - 1s - loss: 2.6818 - accuracy: 0.4250 - 762ms/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "125/125 - 1s - loss: 2.6539 - accuracy: 0.4308 - 742ms/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "125/125 - 1s - loss: 2.6209 - accuracy: 0.4330 - 896ms/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "125/125 - 1s - loss: 2.5918 - accuracy: 0.4463 - 1s/epoch - 10ms/step\n",
            "Epoch 92/200\n",
            "125/125 - 1s - loss: 2.5600 - accuracy: 0.4574 - 1s/epoch - 9ms/step\n",
            "Epoch 93/200\n",
            "125/125 - 1s - loss: 2.5282 - accuracy: 0.4616 - 741ms/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "125/125 - 1s - loss: 2.5000 - accuracy: 0.4732 - 760ms/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "125/125 - 1s - loss: 2.4687 - accuracy: 0.4797 - 778ms/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "125/125 - 1s - loss: 2.4402 - accuracy: 0.4832 - 754ms/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "125/125 - 1s - loss: 2.4102 - accuracy: 0.4920 - 750ms/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "125/125 - 1s - loss: 2.3841 - accuracy: 0.4947 - 757ms/epoch - 6ms/step\n",
            "Epoch 99/200\n",
            "125/125 - 1s - loss: 2.3513 - accuracy: 0.5045 - 762ms/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "125/125 - 1s - loss: 2.3236 - accuracy: 0.5120 - 778ms/epoch - 6ms/step\n",
            "Epoch 101/200\n",
            "125/125 - 1s - loss: 2.2984 - accuracy: 0.5193 - 1s/epoch - 8ms/step\n",
            "Epoch 102/200\n",
            "125/125 - 1s - loss: 2.2689 - accuracy: 0.5281 - 950ms/epoch - 8ms/step\n",
            "Epoch 103/200\n",
            "125/125 - 1s - loss: 2.2421 - accuracy: 0.5309 - 1s/epoch - 9ms/step\n",
            "Epoch 104/200\n",
            "125/125 - 1s - loss: 2.2143 - accuracy: 0.5394 - 1s/epoch - 10ms/step\n",
            "Epoch 105/200\n",
            "125/125 - 2s - loss: 2.1881 - accuracy: 0.5437 - 2s/epoch - 13ms/step\n",
            "Epoch 106/200\n",
            "125/125 - 1s - loss: 2.1583 - accuracy: 0.5517 - 1s/epoch - 10ms/step\n",
            "Epoch 107/200\n",
            "125/125 - 1s - loss: 2.1337 - accuracy: 0.5655 - 1s/epoch - 8ms/step\n",
            "Epoch 108/200\n",
            "125/125 - 1s - loss: 2.1093 - accuracy: 0.5662 - 1s/epoch - 10ms/step\n",
            "Epoch 109/200\n",
            "125/125 - 1s - loss: 2.0833 - accuracy: 0.5760 - 753ms/epoch - 6ms/step\n",
            "Epoch 110/200\n",
            "125/125 - 1s - loss: 2.0581 - accuracy: 0.5840 - 1s/epoch - 9ms/step\n",
            "Epoch 111/200\n",
            "125/125 - 1s - loss: 2.0350 - accuracy: 0.5840 - 1s/epoch - 9ms/step\n",
            "Epoch 112/200\n",
            "125/125 - 1s - loss: 2.0091 - accuracy: 0.5943 - 1s/epoch - 9ms/step\n",
            "Epoch 113/200\n",
            "125/125 - 1s - loss: 1.9856 - accuracy: 0.6009 - 897ms/epoch - 7ms/step\n",
            "Epoch 114/200\n",
            "125/125 - 1s - loss: 1.9617 - accuracy: 0.6041 - 784ms/epoch - 6ms/step\n",
            "Epoch 115/200\n",
            "125/125 - 1s - loss: 1.9383 - accuracy: 0.6056 - 743ms/epoch - 6ms/step\n",
            "Epoch 116/200\n",
            "125/125 - 1s - loss: 1.9139 - accuracy: 0.6109 - 1s/epoch - 9ms/step\n",
            "Epoch 117/200\n",
            "125/125 - 2s - loss: 1.8911 - accuracy: 0.6129 - 2s/epoch - 12ms/step\n",
            "Epoch 118/200\n",
            "125/125 - 1s - loss: 1.8670 - accuracy: 0.6209 - 1s/epoch - 10ms/step\n",
            "Epoch 119/200\n",
            "125/125 - 1s - loss: 1.8439 - accuracy: 0.6287 - 960ms/epoch - 8ms/step\n",
            "Epoch 120/200\n",
            "125/125 - 1s - loss: 1.8217 - accuracy: 0.6322 - 1s/epoch - 9ms/step\n",
            "Epoch 121/200\n",
            "125/125 - 1s - loss: 1.7999 - accuracy: 0.6375 - 755ms/epoch - 6ms/step\n",
            "Epoch 122/200\n",
            "125/125 - 1s - loss: 1.7793 - accuracy: 0.6407 - 763ms/epoch - 6ms/step\n",
            "Epoch 123/200\n",
            "125/125 - 1s - loss: 1.7569 - accuracy: 0.6445 - 750ms/epoch - 6ms/step\n",
            "Epoch 124/200\n",
            "125/125 - 1s - loss: 1.7378 - accuracy: 0.6475 - 811ms/epoch - 6ms/step\n",
            "Epoch 125/200\n",
            "125/125 - 1s - loss: 1.7139 - accuracy: 0.6543 - 760ms/epoch - 6ms/step\n",
            "Epoch 126/200\n",
            "125/125 - 1s - loss: 1.6933 - accuracy: 0.6565 - 744ms/epoch - 6ms/step\n",
            "Epoch 127/200\n",
            "125/125 - 1s - loss: 1.6733 - accuracy: 0.6563 - 733ms/epoch - 6ms/step\n",
            "Epoch 128/200\n",
            "125/125 - 1s - loss: 1.6539 - accuracy: 0.6626 - 735ms/epoch - 6ms/step\n",
            "Epoch 129/200\n",
            "125/125 - 1s - loss: 1.6330 - accuracy: 0.6653 - 746ms/epoch - 6ms/step\n",
            "Epoch 130/200\n",
            "125/125 - 1s - loss: 1.6144 - accuracy: 0.6703 - 1s/epoch - 8ms/step\n",
            "Epoch 131/200\n",
            "125/125 - 1s - loss: 1.5931 - accuracy: 0.6766 - 1s/epoch - 10ms/step\n",
            "Epoch 132/200\n",
            "125/125 - 1s - loss: 1.5737 - accuracy: 0.6821 - 1s/epoch - 9ms/step\n",
            "Epoch 133/200\n",
            "125/125 - 1s - loss: 1.5537 - accuracy: 0.6804 - 768ms/epoch - 6ms/step\n",
            "Epoch 134/200\n",
            "125/125 - 1s - loss: 1.5370 - accuracy: 0.6874 - 766ms/epoch - 6ms/step\n",
            "Epoch 135/200\n",
            "125/125 - 1s - loss: 1.5183 - accuracy: 0.6839 - 745ms/epoch - 6ms/step\n",
            "Epoch 136/200\n",
            "125/125 - 1s - loss: 1.4987 - accuracy: 0.6912 - 741ms/epoch - 6ms/step\n",
            "Epoch 137/200\n",
            "125/125 - 1s - loss: 1.4796 - accuracy: 0.7005 - 770ms/epoch - 6ms/step\n",
            "Epoch 138/200\n",
            "125/125 - 1s - loss: 1.4622 - accuracy: 0.7015 - 771ms/epoch - 6ms/step\n",
            "Epoch 139/200\n",
            "125/125 - 1s - loss: 1.4441 - accuracy: 0.7022 - 759ms/epoch - 6ms/step\n",
            "Epoch 140/200\n",
            "125/125 - 1s - loss: 1.4287 - accuracy: 0.7080 - 720ms/epoch - 6ms/step\n",
            "Epoch 141/200\n",
            "125/125 - 1s - loss: 1.4137 - accuracy: 0.7100 - 748ms/epoch - 6ms/step\n",
            "Epoch 142/200\n",
            "125/125 - 1s - loss: 1.3941 - accuracy: 0.7127 - 722ms/epoch - 6ms/step\n",
            "Epoch 143/200\n",
            "125/125 - 1s - loss: 1.3744 - accuracy: 0.7190 - 773ms/epoch - 6ms/step\n",
            "Epoch 144/200\n",
            "125/125 - 1s - loss: 1.3590 - accuracy: 0.7205 - 754ms/epoch - 6ms/step\n",
            "Epoch 145/200\n",
            "125/125 - 1s - loss: 1.3439 - accuracy: 0.7243 - 839ms/epoch - 7ms/step\n",
            "Epoch 146/200\n",
            "125/125 - 1s - loss: 1.3275 - accuracy: 0.7258 - 1s/epoch - 10ms/step\n",
            "Epoch 147/200\n",
            "125/125 - 1s - loss: 1.3123 - accuracy: 0.7268 - 1s/epoch - 10ms/step\n",
            "Epoch 148/200\n",
            "125/125 - 1s - loss: 1.2956 - accuracy: 0.7353 - 797ms/epoch - 6ms/step\n",
            "Epoch 149/200\n",
            "125/125 - 1s - loss: 1.2810 - accuracy: 0.7338 - 767ms/epoch - 6ms/step\n",
            "Epoch 150/200\n",
            "125/125 - 1s - loss: 1.2670 - accuracy: 0.7401 - 757ms/epoch - 6ms/step\n",
            "Epoch 151/200\n",
            "125/125 - 1s - loss: 1.2516 - accuracy: 0.7431 - 811ms/epoch - 6ms/step\n",
            "Epoch 152/200\n",
            "125/125 - 1s - loss: 1.2394 - accuracy: 0.7459 - 758ms/epoch - 6ms/step\n",
            "Epoch 153/200\n",
            "125/125 - 1s - loss: 1.2254 - accuracy: 0.7459 - 731ms/epoch - 6ms/step\n",
            "Epoch 154/200\n",
            "125/125 - 1s - loss: 1.2085 - accuracy: 0.7479 - 747ms/epoch - 6ms/step\n",
            "Epoch 155/200\n",
            "125/125 - 1s - loss: 1.1946 - accuracy: 0.7456 - 727ms/epoch - 6ms/step\n",
            "Epoch 156/200\n",
            "125/125 - 1s - loss: 1.1793 - accuracy: 0.7549 - 786ms/epoch - 6ms/step\n",
            "Epoch 157/200\n",
            "125/125 - 1s - loss: 1.1646 - accuracy: 0.7597 - 803ms/epoch - 6ms/step\n",
            "Epoch 158/200\n",
            "125/125 - 1s - loss: 1.1510 - accuracy: 0.7551 - 805ms/epoch - 6ms/step\n",
            "Epoch 159/200\n",
            "125/125 - 1s - loss: 1.1363 - accuracy: 0.7607 - 784ms/epoch - 6ms/step\n",
            "Epoch 160/200\n",
            "125/125 - 1s - loss: 1.1239 - accuracy: 0.7669 - 862ms/epoch - 7ms/step\n",
            "Epoch 161/200\n",
            "125/125 - 1s - loss: 1.1124 - accuracy: 0.7644 - 1s/epoch - 10ms/step\n",
            "Epoch 162/200\n",
            "125/125 - 1s - loss: 1.0995 - accuracy: 0.7694 - 1s/epoch - 10ms/step\n",
            "Epoch 163/200\n",
            "125/125 - 1s - loss: 1.0872 - accuracy: 0.7709 - 790ms/epoch - 6ms/step\n",
            "Epoch 164/200\n",
            "125/125 - 1s - loss: 1.0745 - accuracy: 0.7730 - 796ms/epoch - 6ms/step\n",
            "Epoch 165/200\n",
            "125/125 - 1s - loss: 1.0614 - accuracy: 0.7732 - 774ms/epoch - 6ms/step\n",
            "Epoch 166/200\n",
            "125/125 - 1s - loss: 1.0483 - accuracy: 0.7757 - 797ms/epoch - 6ms/step\n",
            "Epoch 167/200\n",
            "125/125 - 1s - loss: 1.0366 - accuracy: 0.7760 - 743ms/epoch - 6ms/step\n",
            "Epoch 168/200\n",
            "125/125 - 1s - loss: 1.0241 - accuracy: 0.7825 - 742ms/epoch - 6ms/step\n",
            "Epoch 169/200\n",
            "125/125 - 1s - loss: 1.0136 - accuracy: 0.7850 - 775ms/epoch - 6ms/step\n",
            "Epoch 170/200\n",
            "125/125 - 1s - loss: 1.0031 - accuracy: 0.7832 - 773ms/epoch - 6ms/step\n",
            "Epoch 171/200\n",
            "125/125 - 1s - loss: 0.9916 - accuracy: 0.7873 - 764ms/epoch - 6ms/step\n",
            "Epoch 172/200\n",
            "125/125 - 1s - loss: 0.9798 - accuracy: 0.7870 - 794ms/epoch - 6ms/step\n",
            "Epoch 173/200\n",
            "125/125 - 1s - loss: 0.9693 - accuracy: 0.7905 - 804ms/epoch - 6ms/step\n",
            "Epoch 174/200\n",
            "125/125 - 1s - loss: 0.9568 - accuracy: 0.7945 - 793ms/epoch - 6ms/step\n",
            "Epoch 175/200\n",
            "125/125 - 1s - loss: 0.9466 - accuracy: 0.7958 - 982ms/epoch - 8ms/step\n",
            "Epoch 176/200\n",
            "125/125 - 1s - loss: 0.9362 - accuracy: 0.7970 - 1s/epoch - 10ms/step\n",
            "Epoch 177/200\n",
            "125/125 - 1s - loss: 0.9283 - accuracy: 0.7965 - 1s/epoch - 9ms/step\n",
            "Epoch 178/200\n",
            "125/125 - 1s - loss: 0.9179 - accuracy: 0.7973 - 800ms/epoch - 6ms/step\n",
            "Epoch 179/200\n",
            "125/125 - 1s - loss: 0.9060 - accuracy: 0.8048 - 1s/epoch - 8ms/step\n",
            "Epoch 180/200\n",
            "125/125 - 1s - loss: 0.8946 - accuracy: 0.8043 - 848ms/epoch - 7ms/step\n",
            "Epoch 181/200\n",
            "125/125 - 1s - loss: 0.8866 - accuracy: 0.8068 - 763ms/epoch - 6ms/step\n",
            "Epoch 182/200\n",
            "125/125 - 1s - loss: 0.8761 - accuracy: 0.8081 - 750ms/epoch - 6ms/step\n",
            "Epoch 183/200\n",
            "125/125 - 1s - loss: 0.8681 - accuracy: 0.8073 - 902ms/epoch - 7ms/step\n",
            "Epoch 184/200\n",
            "125/125 - 1s - loss: 0.8568 - accuracy: 0.8131 - 1s/epoch - 10ms/step\n",
            "Epoch 185/200\n",
            "125/125 - 1s - loss: 0.8490 - accuracy: 0.8096 - 1s/epoch - 11ms/step\n",
            "Epoch 186/200\n",
            "125/125 - 1s - loss: 0.8390 - accuracy: 0.8126 - 1s/epoch - 11ms/step\n",
            "Epoch 187/200\n",
            "125/125 - 2s - loss: 0.8307 - accuracy: 0.8103 - 2s/epoch - 15ms/step\n",
            "Epoch 188/200\n",
            "125/125 - 2s - loss: 0.8211 - accuracy: 0.8154 - 2s/epoch - 15ms/step\n",
            "Epoch 189/200\n",
            "125/125 - 1s - loss: 0.8123 - accuracy: 0.8164 - 1s/epoch - 10ms/step\n",
            "Epoch 190/200\n",
            "125/125 - 1s - loss: 0.8029 - accuracy: 0.8166 - 731ms/epoch - 6ms/step\n",
            "Epoch 191/200\n",
            "125/125 - 1s - loss: 0.7948 - accuracy: 0.8184 - 745ms/epoch - 6ms/step\n",
            "Epoch 192/200\n",
            "125/125 - 1s - loss: 0.7870 - accuracy: 0.8191 - 776ms/epoch - 6ms/step\n",
            "Epoch 193/200\n",
            "125/125 - 1s - loss: 0.7782 - accuracy: 0.8206 - 751ms/epoch - 6ms/step\n",
            "Epoch 194/200\n",
            "125/125 - 1s - loss: 0.7702 - accuracy: 0.8266 - 764ms/epoch - 6ms/step\n",
            "Epoch 195/200\n",
            "125/125 - 1s - loss: 0.7640 - accuracy: 0.8249 - 760ms/epoch - 6ms/step\n",
            "Epoch 196/200\n",
            "125/125 - 1s - loss: 0.7566 - accuracy: 0.8229 - 745ms/epoch - 6ms/step\n",
            "Epoch 197/200\n",
            "125/125 - 1s - loss: 0.7493 - accuracy: 0.8229 - 751ms/epoch - 6ms/step\n",
            "Epoch 198/200\n",
            "125/125 - 1s - loss: 0.7418 - accuracy: 0.8266 - 748ms/epoch - 6ms/step\n",
            "Epoch 199/200\n",
            "125/125 - 1s - loss: 0.7339 - accuracy: 0.8284 - 768ms/epoch - 6ms/step\n",
            "Epoch 200/200\n",
            "125/125 - 1s - loss: 0.7279 - accuracy: 0.8297 - 802ms/epoch - 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c39c2e530>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_seq(model, tokenizer, max_length-1, 'स्वास्थ्य सेवा', 3))\n",
        "print(generate_seq(model, tokenizer, max_length-1, 'कश्मीर के', 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb4LJr851J6I",
        "outputId": "b6124971-22d0-4932-b06b-67d91aa35010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "स्वास्थ्य सेवा पहुचाते थे ।\n",
            "कश्मीर के उत्परिवर्तन\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
        "model2.add(LSTM(100, return_sequences=True))\n",
        "model2.add(LSTM(50))\n",
        "model2.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.fit(X_train, y_train, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQGpx3JGKz_4",
        "outputId": "39a50dbc-c7d8-4937-8216-90903eaa6d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "125/125 - 6s - loss: 7.1060 - accuracy: 0.0416 - 6s/epoch - 48ms/step\n",
            "Epoch 2/200\n",
            "125/125 - 1s - loss: 6.4061 - accuracy: 0.0442 - 1s/epoch - 9ms/step\n",
            "Epoch 3/200\n",
            "125/125 - 1s - loss: 6.3004 - accuracy: 0.0442 - 1s/epoch - 9ms/step\n",
            "Epoch 4/200\n",
            "125/125 - 1s - loss: 6.2161 - accuracy: 0.0442 - 1s/epoch - 9ms/step\n",
            "Epoch 5/200\n",
            "125/125 - 1s - loss: 6.1563 - accuracy: 0.0442 - 1s/epoch - 9ms/step\n",
            "Epoch 6/200\n",
            "125/125 - 1s - loss: 6.1221 - accuracy: 0.0394 - 1s/epoch - 9ms/step\n",
            "Epoch 7/200\n",
            "125/125 - 1s - loss: 6.0963 - accuracy: 0.0444 - 1s/epoch - 9ms/step\n",
            "Epoch 8/200\n",
            "125/125 - 2s - loss: 6.0739 - accuracy: 0.0442 - 2s/epoch - 19ms/step\n",
            "Epoch 9/200\n",
            "125/125 - 1s - loss: 6.0512 - accuracy: 0.0444 - 1s/epoch - 11ms/step\n",
            "Epoch 10/200\n",
            "125/125 - 1s - loss: 6.0337 - accuracy: 0.0419 - 1s/epoch - 9ms/step\n",
            "Epoch 11/200\n",
            "125/125 - 1s - loss: 6.0104 - accuracy: 0.0444 - 1s/epoch - 9ms/step\n",
            "Epoch 12/200\n",
            "125/125 - 1s - loss: 5.9801 - accuracy: 0.0439 - 1s/epoch - 9ms/step\n",
            "Epoch 13/200\n",
            "125/125 - 1s - loss: 5.9400 - accuracy: 0.0459 - 1s/epoch - 9ms/step\n",
            "Epoch 14/200\n",
            "125/125 - 1s - loss: 5.8631 - accuracy: 0.0472 - 1s/epoch - 9ms/step\n",
            "Epoch 15/200\n",
            "125/125 - 1s - loss: 5.7478 - accuracy: 0.0444 - 1s/epoch - 9ms/step\n",
            "Epoch 16/200\n",
            "125/125 - 1s - loss: 5.6393 - accuracy: 0.0452 - 1s/epoch - 9ms/step\n",
            "Epoch 17/200\n",
            "125/125 - 1s - loss: 5.5474 - accuracy: 0.0442 - 1s/epoch - 9ms/step\n",
            "Epoch 18/200\n",
            "125/125 - 2s - loss: 5.4577 - accuracy: 0.0499 - 2s/epoch - 14ms/step\n",
            "Epoch 19/200\n",
            "125/125 - 2s - loss: 5.3639 - accuracy: 0.0564 - 2s/epoch - 12ms/step\n",
            "Epoch 20/200\n",
            "125/125 - 1s - loss: 5.2732 - accuracy: 0.0547 - 1s/epoch - 9ms/step\n",
            "Epoch 21/200\n",
            "125/125 - 1s - loss: 5.1756 - accuracy: 0.0602 - 1s/epoch - 9ms/step\n",
            "Epoch 22/200\n",
            "125/125 - 1s - loss: 5.0840 - accuracy: 0.0647 - 1s/epoch - 9ms/step\n",
            "Epoch 23/200\n",
            "125/125 - 1s - loss: 4.9998 - accuracy: 0.0702 - 1s/epoch - 9ms/step\n",
            "Epoch 24/200\n",
            "125/125 - 1s - loss: 4.9209 - accuracy: 0.0740 - 1s/epoch - 9ms/step\n",
            "Epoch 25/200\n",
            "125/125 - 1s - loss: 4.8422 - accuracy: 0.0793 - 1s/epoch - 9ms/step\n",
            "Epoch 26/200\n",
            "125/125 - 1s - loss: 4.7719 - accuracy: 0.0840 - 1s/epoch - 9ms/step\n",
            "Epoch 27/200\n",
            "125/125 - 1s - loss: 4.7075 - accuracy: 0.0911 - 1s/epoch - 9ms/step\n",
            "Epoch 28/200\n",
            "125/125 - 1s - loss: 4.6483 - accuracy: 0.0948 - 1s/epoch - 11ms/step\n",
            "Epoch 29/200\n",
            "125/125 - 2s - loss: 4.5922 - accuracy: 0.0961 - 2s/epoch - 14ms/step\n",
            "Epoch 30/200\n",
            "125/125 - 1s - loss: 4.5352 - accuracy: 0.1016 - 1s/epoch - 9ms/step\n",
            "Epoch 31/200\n",
            "125/125 - 1s - loss: 4.4833 - accuracy: 0.1006 - 1s/epoch - 9ms/step\n",
            "Epoch 32/200\n",
            "125/125 - 1s - loss: 4.4324 - accuracy: 0.1069 - 1s/epoch - 9ms/step\n",
            "Epoch 33/200\n",
            "125/125 - 1s - loss: 4.3821 - accuracy: 0.1136 - 1s/epoch - 9ms/step\n",
            "Epoch 34/200\n",
            "125/125 - 1s - loss: 4.3361 - accuracy: 0.1164 - 1s/epoch - 9ms/step\n",
            "Epoch 35/200\n",
            "125/125 - 1s - loss: 4.2927 - accuracy: 0.1229 - 1s/epoch - 9ms/step\n",
            "Epoch 36/200\n",
            "125/125 - 1s - loss: 4.2475 - accuracy: 0.1224 - 1s/epoch - 9ms/step\n",
            "Epoch 37/200\n",
            "125/125 - 1s - loss: 4.2022 - accuracy: 0.1274 - 1s/epoch - 9ms/step\n",
            "Epoch 38/200\n",
            "125/125 - 1s - loss: 4.1617 - accuracy: 0.1355 - 1s/epoch - 9ms/step\n",
            "Epoch 39/200\n",
            "125/125 - 2s - loss: 4.1228 - accuracy: 0.1380 - 2s/epoch - 13ms/step\n",
            "Epoch 40/200\n",
            "125/125 - 2s - loss: 4.0842 - accuracy: 0.1395 - 2s/epoch - 12ms/step\n",
            "Epoch 41/200\n",
            "125/125 - 2s - loss: 4.0460 - accuracy: 0.1468 - 2s/epoch - 15ms/step\n",
            "Epoch 42/200\n",
            "125/125 - 2s - loss: 4.0112 - accuracy: 0.1508 - 2s/epoch - 18ms/step\n",
            "Epoch 43/200\n",
            "125/125 - 2s - loss: 3.9701 - accuracy: 0.1550 - 2s/epoch - 17ms/step\n",
            "Epoch 44/200\n",
            "125/125 - 1s - loss: 3.9309 - accuracy: 0.1586 - 1s/epoch - 11ms/step\n",
            "Epoch 45/200\n",
            "125/125 - 1s - loss: 3.8966 - accuracy: 0.1628 - 1s/epoch - 9ms/step\n",
            "Epoch 46/200\n",
            "125/125 - 1s - loss: 3.8640 - accuracy: 0.1658 - 1s/epoch - 11ms/step\n",
            "Epoch 47/200\n",
            "125/125 - 3s - loss: 3.8272 - accuracy: 0.1706 - 3s/epoch - 21ms/step\n",
            "Epoch 48/200\n",
            "125/125 - 1s - loss: 3.7977 - accuracy: 0.1736 - 1s/epoch - 11ms/step\n",
            "Epoch 49/200\n",
            "125/125 - 2s - loss: 3.7608 - accuracy: 0.1796 - 2s/epoch - 14ms/step\n",
            "Epoch 50/200\n",
            "125/125 - 3s - loss: 3.7263 - accuracy: 0.1867 - 3s/epoch - 21ms/step\n",
            "Epoch 51/200\n",
            "125/125 - 2s - loss: 3.6951 - accuracy: 0.1859 - 2s/epoch - 13ms/step\n",
            "Epoch 52/200\n",
            "125/125 - 1s - loss: 3.6668 - accuracy: 0.1897 - 1s/epoch - 11ms/step\n",
            "Epoch 53/200\n",
            "125/125 - 2s - loss: 3.6333 - accuracy: 0.1934 - 2s/epoch - 19ms/step\n",
            "Epoch 54/200\n",
            "125/125 - 3s - loss: 3.6033 - accuracy: 0.1987 - 3s/epoch - 23ms/step\n",
            "Epoch 55/200\n",
            "125/125 - 2s - loss: 3.5688 - accuracy: 0.2057 - 2s/epoch - 15ms/step\n",
            "Epoch 56/200\n",
            "125/125 - 1s - loss: 3.5408 - accuracy: 0.2055 - 1s/epoch - 10ms/step\n",
            "Epoch 57/200\n",
            "125/125 - 1s - loss: 3.5107 - accuracy: 0.2115 - 1s/epoch - 9ms/step\n",
            "Epoch 58/200\n",
            "125/125 - 1s - loss: 3.4815 - accuracy: 0.2155 - 1s/epoch - 9ms/step\n",
            "Epoch 59/200\n",
            "125/125 - 1s - loss: 3.4510 - accuracy: 0.2195 - 1s/epoch - 9ms/step\n",
            "Epoch 60/200\n",
            "125/125 - 2s - loss: 3.4283 - accuracy: 0.2208 - 2s/epoch - 12ms/step\n",
            "Epoch 61/200\n",
            "125/125 - 1s - loss: 3.4010 - accuracy: 0.2278 - 1s/epoch - 9ms/step\n",
            "Epoch 62/200\n",
            "125/125 - 2s - loss: 3.3665 - accuracy: 0.2288 - 2s/epoch - 20ms/step\n",
            "Epoch 63/200\n",
            "125/125 - 1s - loss: 3.3450 - accuracy: 0.2371 - 1s/epoch - 11ms/step\n",
            "Epoch 64/200\n",
            "125/125 - 1s - loss: 3.3124 - accuracy: 0.2378 - 1s/epoch - 9ms/step\n",
            "Epoch 65/200\n",
            "125/125 - 1s - loss: 3.2888 - accuracy: 0.2454 - 1s/epoch - 11ms/step\n",
            "Epoch 66/200\n",
            "125/125 - 2s - loss: 3.2583 - accuracy: 0.2436 - 2s/epoch - 12ms/step\n",
            "Epoch 67/200\n",
            "125/125 - 1s - loss: 3.2284 - accuracy: 0.2549 - 1s/epoch - 9ms/step\n",
            "Epoch 68/200\n",
            "125/125 - 1s - loss: 3.2074 - accuracy: 0.2566 - 1s/epoch - 9ms/step\n",
            "Epoch 69/200\n",
            "125/125 - 1s - loss: 3.1807 - accuracy: 0.2589 - 1s/epoch - 9ms/step\n",
            "Epoch 70/200\n",
            "125/125 - 1s - loss: 3.1610 - accuracy: 0.2642 - 1s/epoch - 9ms/step\n",
            "Epoch 71/200\n",
            "125/125 - 2s - loss: 3.1283 - accuracy: 0.2747 - 2s/epoch - 12ms/step\n",
            "Epoch 72/200\n",
            "125/125 - 2s - loss: 3.1042 - accuracy: 0.2750 - 2s/epoch - 14ms/step\n",
            "Epoch 73/200\n",
            "125/125 - 1s - loss: 3.0779 - accuracy: 0.2790 - 1s/epoch - 9ms/step\n",
            "Epoch 74/200\n",
            "125/125 - 1s - loss: 3.0464 - accuracy: 0.2910 - 1s/epoch - 9ms/step\n",
            "Epoch 75/200\n",
            "125/125 - 1s - loss: 3.0170 - accuracy: 0.2928 - 1s/epoch - 9ms/step\n",
            "Epoch 76/200\n",
            "125/125 - 1s - loss: 2.9970 - accuracy: 0.2993 - 1s/epoch - 9ms/step\n",
            "Epoch 77/200\n",
            "125/125 - 1s - loss: 2.9706 - accuracy: 0.3066 - 1s/epoch - 9ms/step\n",
            "Epoch 78/200\n",
            "125/125 - 1s - loss: 2.9479 - accuracy: 0.3073 - 1s/epoch - 9ms/step\n",
            "Epoch 79/200\n",
            "125/125 - 1s - loss: 2.9280 - accuracy: 0.3171 - 1s/epoch - 9ms/step\n",
            "Epoch 80/200\n",
            "125/125 - 1s - loss: 2.9014 - accuracy: 0.3211 - 1s/epoch - 9ms/step\n",
            "Epoch 81/200\n",
            "125/125 - 1s - loss: 2.8780 - accuracy: 0.3271 - 1s/epoch - 10ms/step\n",
            "Epoch 82/200\n",
            "125/125 - 2s - loss: 2.8570 - accuracy: 0.3304 - 2s/epoch - 14ms/step\n",
            "Epoch 83/200\n",
            "125/125 - 1s - loss: 2.8346 - accuracy: 0.3339 - 1s/epoch - 11ms/step\n",
            "Epoch 84/200\n",
            "125/125 - 1s - loss: 2.8097 - accuracy: 0.3437 - 1s/epoch - 9ms/step\n",
            "Epoch 85/200\n",
            "125/125 - 1s - loss: 2.7896 - accuracy: 0.3432 - 1s/epoch - 9ms/step\n",
            "Epoch 86/200\n",
            "125/125 - 1s - loss: 2.7631 - accuracy: 0.3482 - 1s/epoch - 9ms/step\n",
            "Epoch 87/200\n",
            "125/125 - 1s - loss: 2.7418 - accuracy: 0.3570 - 1s/epoch - 9ms/step\n",
            "Epoch 88/200\n",
            "125/125 - 1s - loss: 2.7216 - accuracy: 0.3550 - 1s/epoch - 9ms/step\n",
            "Epoch 89/200\n",
            "125/125 - 1s - loss: 2.6924 - accuracy: 0.3645 - 1s/epoch - 9ms/step\n",
            "Epoch 90/200\n",
            "125/125 - 1s - loss: 2.6822 - accuracy: 0.3675 - 1s/epoch - 9ms/step\n",
            "Epoch 91/200\n",
            "125/125 - 1s - loss: 2.6576 - accuracy: 0.3680 - 1s/epoch - 9ms/step\n",
            "Epoch 92/200\n",
            "125/125 - 2s - loss: 2.6366 - accuracy: 0.3718 - 2s/epoch - 12ms/step\n",
            "Epoch 93/200\n",
            "125/125 - 2s - loss: 2.6135 - accuracy: 0.3828 - 2s/epoch - 14ms/step\n",
            "Epoch 94/200\n",
            "125/125 - 1s - loss: 2.5953 - accuracy: 0.3899 - 1s/epoch - 9ms/step\n",
            "Epoch 95/200\n",
            "125/125 - 1s - loss: 2.5742 - accuracy: 0.3861 - 1s/epoch - 9ms/step\n",
            "Epoch 96/200\n",
            "125/125 - 1s - loss: 2.5533 - accuracy: 0.3929 - 1s/epoch - 9ms/step\n",
            "Epoch 97/200\n",
            "125/125 - 1s - loss: 2.5341 - accuracy: 0.3994 - 1s/epoch - 9ms/step\n",
            "Epoch 98/200\n",
            "125/125 - 1s - loss: 2.5057 - accuracy: 0.4104 - 1s/epoch - 9ms/step\n",
            "Epoch 99/200\n",
            "125/125 - 1s - loss: 2.4845 - accuracy: 0.4074 - 1s/epoch - 9ms/step\n",
            "Epoch 100/200\n",
            "125/125 - 1s - loss: 2.4693 - accuracy: 0.4190 - 1s/epoch - 9ms/step\n",
            "Epoch 101/200\n",
            "125/125 - 1s - loss: 2.4560 - accuracy: 0.4127 - 1s/epoch - 9ms/step\n",
            "Epoch 102/200\n",
            "125/125 - 1s - loss: 2.4433 - accuracy: 0.4162 - 1s/epoch - 11ms/step\n",
            "Epoch 103/200\n",
            "125/125 - 2s - loss: 2.4226 - accuracy: 0.4177 - 2s/epoch - 14ms/step\n",
            "Epoch 104/200\n",
            "125/125 - 1s - loss: 2.4046 - accuracy: 0.4293 - 1s/epoch - 10ms/step\n",
            "Epoch 105/200\n",
            "125/125 - 1s - loss: 2.3824 - accuracy: 0.4355 - 1s/epoch - 9ms/step\n",
            "Epoch 106/200\n",
            "125/125 - 1s - loss: 2.3724 - accuracy: 0.4338 - 1s/epoch - 9ms/step\n",
            "Epoch 107/200\n",
            "125/125 - 1s - loss: 2.3517 - accuracy: 0.4428 - 1s/epoch - 9ms/step\n",
            "Epoch 108/200\n",
            "125/125 - 1s - loss: 2.3289 - accuracy: 0.4428 - 1s/epoch - 9ms/step\n",
            "Epoch 109/200\n",
            "125/125 - 1s - loss: 2.3144 - accuracy: 0.4491 - 1s/epoch - 9ms/step\n",
            "Epoch 110/200\n",
            "125/125 - 1s - loss: 2.2969 - accuracy: 0.4521 - 1s/epoch - 9ms/step\n",
            "Epoch 111/200\n",
            "125/125 - 1s - loss: 2.2780 - accuracy: 0.4579 - 1s/epoch - 9ms/step\n",
            "Epoch 112/200\n",
            "125/125 - 1s - loss: 2.2622 - accuracy: 0.4644 - 1s/epoch - 9ms/step\n",
            "Epoch 113/200\n",
            "125/125 - 2s - loss: 2.2497 - accuracy: 0.4671 - 2s/epoch - 13ms/step\n",
            "Epoch 114/200\n",
            "125/125 - 2s - loss: 2.2385 - accuracy: 0.4696 - 2s/epoch - 13ms/step\n",
            "Epoch 115/200\n",
            "125/125 - 1s - loss: 2.2224 - accuracy: 0.4779 - 1s/epoch - 9ms/step\n",
            "Epoch 116/200\n",
            "125/125 - 1s - loss: 2.2102 - accuracy: 0.4704 - 1s/epoch - 9ms/step\n",
            "Epoch 117/200\n",
            "125/125 - 1s - loss: 2.1885 - accuracy: 0.4819 - 1s/epoch - 9ms/step\n",
            "Epoch 118/200\n",
            "125/125 - 1s - loss: 2.1662 - accuracy: 0.4890 - 1s/epoch - 9ms/step\n",
            "Epoch 119/200\n",
            "125/125 - 1s - loss: 2.1495 - accuracy: 0.4867 - 1s/epoch - 9ms/step\n",
            "Epoch 120/200\n",
            "125/125 - 1s - loss: 2.1370 - accuracy: 0.4915 - 1s/epoch - 9ms/step\n",
            "Epoch 121/200\n",
            "125/125 - 1s - loss: 2.1246 - accuracy: 0.4950 - 1s/epoch - 9ms/step\n",
            "Epoch 122/200\n",
            "125/125 - 1s - loss: 2.1075 - accuracy: 0.4907 - 1s/epoch - 9ms/step\n",
            "Epoch 123/200\n",
            "125/125 - 1s - loss: 2.0906 - accuracy: 0.5100 - 1s/epoch - 10ms/step\n",
            "Epoch 124/200\n",
            "125/125 - 2s - loss: 2.0823 - accuracy: 0.5083 - 2s/epoch - 14ms/step\n",
            "Epoch 125/200\n",
            "125/125 - 1s - loss: 2.0738 - accuracy: 0.5023 - 1s/epoch - 10ms/step\n",
            "Epoch 126/200\n",
            "125/125 - 1s - loss: 2.0590 - accuracy: 0.5090 - 1s/epoch - 9ms/step\n",
            "Epoch 127/200\n",
            "125/125 - 1s - loss: 2.0404 - accuracy: 0.5156 - 1s/epoch - 9ms/step\n",
            "Epoch 128/200\n",
            "125/125 - 1s - loss: 2.0185 - accuracy: 0.5176 - 1s/epoch - 9ms/step\n",
            "Epoch 129/200\n",
            "125/125 - 1s - loss: 1.9979 - accuracy: 0.5266 - 1s/epoch - 9ms/step\n",
            "Epoch 130/200\n",
            "125/125 - 1s - loss: 1.9926 - accuracy: 0.5251 - 1s/epoch - 9ms/step\n",
            "Epoch 131/200\n",
            "125/125 - 1s - loss: 1.9818 - accuracy: 0.5281 - 1s/epoch - 9ms/step\n",
            "Epoch 132/200\n",
            "125/125 - 1s - loss: 1.9683 - accuracy: 0.5299 - 1s/epoch - 9ms/step\n",
            "Epoch 133/200\n",
            "125/125 - 1s - loss: 1.9547 - accuracy: 0.5314 - 1s/epoch - 9ms/step\n",
            "Epoch 134/200\n",
            "125/125 - 2s - loss: 1.9422 - accuracy: 0.5324 - 2s/epoch - 14ms/step\n",
            "Epoch 135/200\n",
            "125/125 - 2s - loss: 1.9366 - accuracy: 0.5361 - 2s/epoch - 13ms/step\n",
            "Epoch 136/200\n",
            "125/125 - 1s - loss: 1.9267 - accuracy: 0.5316 - 1s/epoch - 9ms/step\n",
            "Epoch 137/200\n",
            "125/125 - 1s - loss: 1.9061 - accuracy: 0.5462 - 1s/epoch - 9ms/step\n",
            "Epoch 138/200\n",
            "125/125 - 1s - loss: 1.8851 - accuracy: 0.5469 - 1s/epoch - 9ms/step\n",
            "Epoch 139/200\n",
            "125/125 - 1s - loss: 1.8676 - accuracy: 0.5559 - 1s/epoch - 9ms/step\n",
            "Epoch 140/200\n",
            "125/125 - 1s - loss: 1.8567 - accuracy: 0.5549 - 1s/epoch - 9ms/step\n",
            "Epoch 141/200\n",
            "125/125 - 1s - loss: 1.8446 - accuracy: 0.5527 - 1s/epoch - 9ms/step\n",
            "Epoch 142/200\n",
            "125/125 - 1s - loss: 1.8350 - accuracy: 0.5597 - 1s/epoch - 9ms/step\n",
            "Epoch 143/200\n",
            "125/125 - 1s - loss: 1.8228 - accuracy: 0.5585 - 1s/epoch - 9ms/step\n",
            "Epoch 144/200\n",
            "125/125 - 1s - loss: 1.8229 - accuracy: 0.5625 - 1s/epoch - 10ms/step\n",
            "Epoch 145/200\n",
            "125/125 - 2s - loss: 1.8090 - accuracy: 0.5630 - 2s/epoch - 14ms/step\n",
            "Epoch 146/200\n",
            "125/125 - 1s - loss: 1.8026 - accuracy: 0.5677 - 1s/epoch - 10ms/step\n",
            "Epoch 147/200\n",
            "125/125 - 1s - loss: 1.7868 - accuracy: 0.5682 - 1s/epoch - 9ms/step\n",
            "Epoch 148/200\n",
            "125/125 - 1s - loss: 1.7712 - accuracy: 0.5758 - 1s/epoch - 9ms/step\n",
            "Epoch 149/200\n",
            "125/125 - 1s - loss: 1.7618 - accuracy: 0.5795 - 1s/epoch - 9ms/step\n",
            "Epoch 150/200\n",
            "125/125 - 1s - loss: 1.7456 - accuracy: 0.5765 - 1s/epoch - 9ms/step\n",
            "Epoch 151/200\n",
            "125/125 - 1s - loss: 1.7321 - accuracy: 0.5783 - 1s/epoch - 9ms/step\n",
            "Epoch 152/200\n",
            "125/125 - 1s - loss: 1.7133 - accuracy: 0.5850 - 1s/epoch - 9ms/step\n",
            "Epoch 153/200\n",
            "125/125 - 1s - loss: 1.7093 - accuracy: 0.5881 - 1s/epoch - 10ms/step\n",
            "Epoch 154/200\n",
            "125/125 - 1s - loss: 1.6948 - accuracy: 0.5933 - 1s/epoch - 11ms/step\n",
            "Epoch 155/200\n",
            "125/125 - 2s - loss: 1.6853 - accuracy: 0.5926 - 2s/epoch - 14ms/step\n",
            "Epoch 156/200\n",
            "125/125 - 1s - loss: 1.6717 - accuracy: 0.5951 - 1s/epoch - 11ms/step\n",
            "Epoch 157/200\n",
            "125/125 - 1s - loss: 1.6647 - accuracy: 0.5966 - 1s/epoch - 9ms/step\n",
            "Epoch 158/200\n",
            "125/125 - 1s - loss: 1.6576 - accuracy: 0.5951 - 1s/epoch - 9ms/step\n",
            "Epoch 159/200\n",
            "125/125 - 1s - loss: 1.6360 - accuracy: 0.6056 - 1s/epoch - 9ms/step\n",
            "Epoch 160/200\n",
            "125/125 - 1s - loss: 1.6274 - accuracy: 0.6106 - 1s/epoch - 9ms/step\n",
            "Epoch 161/200\n",
            "125/125 - 1s - loss: 1.6211 - accuracy: 0.6064 - 1s/epoch - 9ms/step\n",
            "Epoch 162/200\n",
            "125/125 - 1s - loss: 1.6209 - accuracy: 0.6074 - 1s/epoch - 9ms/step\n",
            "Epoch 163/200\n",
            "125/125 - 1s - loss: 1.6078 - accuracy: 0.6134 - 1s/epoch - 9ms/step\n",
            "Epoch 164/200\n",
            "125/125 - 1s - loss: 1.5990 - accuracy: 0.6074 - 1s/epoch - 9ms/step\n",
            "Epoch 165/200\n",
            "125/125 - 2s - loss: 1.5898 - accuracy: 0.6121 - 2s/epoch - 12ms/step\n",
            "Epoch 166/200\n",
            "125/125 - 2s - loss: 1.5797 - accuracy: 0.6159 - 2s/epoch - 13ms/step\n",
            "Epoch 167/200\n",
            "125/125 - 1s - loss: 1.5685 - accuracy: 0.6254 - 1s/epoch - 9ms/step\n",
            "Epoch 168/200\n",
            "125/125 - 1s - loss: 1.5656 - accuracy: 0.6222 - 1s/epoch - 9ms/step\n",
            "Epoch 169/200\n",
            "125/125 - 1s - loss: 1.5515 - accuracy: 0.6237 - 1s/epoch - 9ms/step\n",
            "Epoch 170/200\n",
            "125/125 - 1s - loss: 1.5401 - accuracy: 0.6207 - 1s/epoch - 9ms/step\n",
            "Epoch 171/200\n",
            "125/125 - 1s - loss: 1.5326 - accuracy: 0.6272 - 1s/epoch - 9ms/step\n",
            "Epoch 172/200\n",
            "125/125 - 1s - loss: 1.5236 - accuracy: 0.6290 - 1s/epoch - 9ms/step\n",
            "Epoch 173/200\n",
            "125/125 - 1s - loss: 1.5078 - accuracy: 0.6337 - 1s/epoch - 9ms/step\n",
            "Epoch 174/200\n",
            "125/125 - 1s - loss: 1.4913 - accuracy: 0.6438 - 1s/epoch - 11ms/step\n",
            "Epoch 175/200\n",
            "125/125 - 1s - loss: 1.4812 - accuracy: 0.6450 - 1s/epoch - 11ms/step\n",
            "Epoch 176/200\n",
            "125/125 - 2s - loss: 1.4721 - accuracy: 0.6448 - 2s/epoch - 14ms/step\n",
            "Epoch 177/200\n",
            "125/125 - 1s - loss: 1.4711 - accuracy: 0.6488 - 1s/epoch - 10ms/step\n",
            "Epoch 178/200\n",
            "125/125 - 1s - loss: 1.4587 - accuracy: 0.6470 - 1s/epoch - 9ms/step\n",
            "Epoch 179/200\n",
            "125/125 - 1s - loss: 1.4471 - accuracy: 0.6523 - 1s/epoch - 9ms/step\n",
            "Epoch 180/200\n",
            "125/125 - 1s - loss: 1.4439 - accuracy: 0.6515 - 1s/epoch - 9ms/step\n",
            "Epoch 181/200\n",
            "125/125 - 1s - loss: 1.4376 - accuracy: 0.6558 - 1s/epoch - 9ms/step\n",
            "Epoch 182/200\n",
            "125/125 - 1s - loss: 1.4270 - accuracy: 0.6578 - 1s/epoch - 9ms/step\n",
            "Epoch 183/200\n",
            "125/125 - 1s - loss: 1.4197 - accuracy: 0.6560 - 1s/epoch - 9ms/step\n",
            "Epoch 184/200\n",
            "125/125 - 1s - loss: 1.4059 - accuracy: 0.6651 - 1s/epoch - 9ms/step\n",
            "Epoch 185/200\n",
            "125/125 - 1s - loss: 1.3989 - accuracy: 0.6648 - 1s/epoch - 10ms/step\n",
            "Epoch 186/200\n",
            "125/125 - 2s - loss: 1.3942 - accuracy: 0.6646 - 2s/epoch - 14ms/step\n",
            "Epoch 187/200\n",
            "125/125 - 2s - loss: 1.3870 - accuracy: 0.6656 - 2s/epoch - 12ms/step\n",
            "Epoch 188/200\n",
            "125/125 - 1s - loss: 1.3793 - accuracy: 0.6706 - 1s/epoch - 9ms/step\n",
            "Epoch 189/200\n",
            "125/125 - 1s - loss: 1.3697 - accuracy: 0.6651 - 1s/epoch - 9ms/step\n",
            "Epoch 190/200\n",
            "125/125 - 1s - loss: 1.3612 - accuracy: 0.6719 - 1s/epoch - 9ms/step\n",
            "Epoch 191/200\n",
            "125/125 - 1s - loss: 1.3479 - accuracy: 0.6754 - 1s/epoch - 9ms/step\n",
            "Epoch 192/200\n",
            "125/125 - 1s - loss: 1.3443 - accuracy: 0.6751 - 1s/epoch - 10ms/step\n",
            "Epoch 193/200\n",
            "125/125 - 1s - loss: 1.3372 - accuracy: 0.6764 - 1s/epoch - 9ms/step\n",
            "Epoch 194/200\n",
            "125/125 - 1s - loss: 1.3331 - accuracy: 0.6824 - 1s/epoch - 9ms/step\n",
            "Epoch 195/200\n",
            "125/125 - 1s - loss: 1.3252 - accuracy: 0.6799 - 1s/epoch - 10ms/step\n",
            "Epoch 196/200\n",
            "125/125 - 2s - loss: 1.3133 - accuracy: 0.6796 - 2s/epoch - 12ms/step\n",
            "Epoch 197/200\n",
            "125/125 - 2s - loss: 1.3055 - accuracy: 0.6846 - 2s/epoch - 14ms/step\n",
            "Epoch 198/200\n",
            "125/125 - 1s - loss: 1.3058 - accuracy: 0.6859 - 1s/epoch - 9ms/step\n",
            "Epoch 199/200\n",
            "125/125 - 1s - loss: 1.2942 - accuracy: 0.6862 - 1s/epoch - 9ms/step\n",
            "Epoch 200/200\n",
            "125/125 - 1s - loss: 1.2886 - accuracy: 0.6907 - 1s/epoch - 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c390beb60>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_seq(model2, tokenizer, max_length-1, 'स्वास्थ्य सेवा', 3))\n",
        "print(generate_seq(model2, tokenizer, max_length-1, 'कश्मीर के', 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWrNGaYILmKY",
        "outputId": "07c5b1d8-1e4d-46b9-9be4-59e6847e3961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "स्वास्थ्य सेवा पहुचाते हे घरों\n",
            "कश्मीर के भागों\n"
          ]
        }
      ]
    }
  ]
}